<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="description" content="" />
		<link rel="icon" href="/favicon.png" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		

		

		<link rel="stylesheet" href="/_app/assets/start-61d1577b.css">
		<link rel="modulepreload" href="/_app/start-c09d08cd.js">
		<link rel="modulepreload" href="/_app/chunks/vendor-9b9d6288.js">
		<link rel="modulepreload" href="/_app/pages/__layout.svelte-de46afb2.js">
		<link rel="modulepreload" href="/_app/pages/_lang_/__layout.svelte-e75718c6.js">
		<link rel="modulepreload" href="/_app/chunks/stores-191d1505.js">
		<link rel="modulepreload" href="/_app/pages/_lang_/_lessons_/_slug_/index.svelte-efe77d76.js">

		<script type="module">
			import { start } from "/_app/start-c09d08cd.js";
			start({
				target: document.querySelector("#svelte"),
				paths: {"base":"","assets":""},
				session: {},
				route: true,
				spa: false,
				trailing_slash: "never",
				hydrate: {
					status: 200,
					error: null,
					nodes: [
						import("/_app/pages/__layout.svelte-de46afb2.js"),
						import("/_app/pages/_lang_/__layout.svelte-e75718c6.js"),
						import("/_app/pages/_lang_/_lessons_/_slug_/index.svelte-efe77d76.js")
					],
					url: new URL("sveltekit://prerender/en/lessons/geoparsing-text-with-edinburgh"),
					params: {lang:"en",lessons:"lessons",slug:"geoparsing-text-with-edinburgh"}
				}
			});
		</script><script>
			if ('serviceWorker' in navigator) {
				navigator.serviceWorker.register('/service-worker.js');
			}
		</script>
	</head>
	<body>
		<div id="svelte">


The Programming Historian <a href="/en">English</a> <a href="/es">Spanish</a>
<br>
This is the en edition.

<h1>Geoparsing English-Language Text with the Edinburgh Geoparser</h1>

<!-- HTML_TAG_START --><p>{% include toc.html %}</p>
<h2 id="introduction">Introduction</h2>
<p>This is a lesson on how to use the <a href="https://www.ltg.ed.ac.uk/software/geoparser/">Edinburgh Geoparser</a>.  The Geoparser allows you to process a piece of English-language text and extract and resolve the locations contained within it. Among other uses, geo-resolution of locations makes it possible to map the data.</p>
<p>The Geoparser works best on running text, as it considers locations in context for disambiguation. For example, if you would like to get a sense of the place names mentioned in a piece of text, the Geoparser can be used to identify terms in a document that are likely to refer to place names.  It will then provide its best guess as to where those places are in terms of latitute/longitude coordinates.</p>
<p>In December 2015, the Edinburgh Geoparser was released under the University of Edinburgh’s GPL license to be used by other researchers in the field of text mining as well as other scholars who are interested in geoparsing text. More information on its documentation, publications about it and how to download it can be found <a href="https://www.ltg.ed.ac.uk/software/geoparser/">here</a>.</p>
<p>A simple online demo of the vanilla Edinburgh Geoparser can be tried out <a href="http://jekyll.inf.ed.ac.uk/geoparser.html">here</a>. It provides only the visual interface to the Geoparser output after uploading a text file and selecting a gazetteer.  The demo is otherwise not configurable and should only be used to try out small examples and not for geo-parsing a large number of files.</p>
<p>The following lesson explains how the Edinburgh Geoparser works under the hood and contains information on:</p>
<ul>
<li>Prerequisites and terminology</li>
<li>Downloading and setting up the Edinbugh Geoparser,</li>
<li>Geo-parsing a text file,</li>
<li>Other useful options for running the Geoparser,</li>
<li>Geo-parsing multiple text files, and</li>
<li>Extracting geo-resolution output to TSV.</li>
</ul>
<h2 id="prerequisites-and-terminology">Prerequisites and Terminology</h2>
<p>This lesson requires users to be familiar with the command line.  If not then you should follow the lesson <a href="/lessons/intro-to-bash">Introduction to the Bash Command Line</a> first.</p>
<p>The Geoparser works on MacOS or Linux but is not supported for Windows. The following lesson provides command line instructions for MacOSX users and equivalent commands for Linux users (only if different to the Mac versions). Note that if your machine is running macOS Sierra (Darwin 16.7.0) or later versions then you need to apply a temporary <a href="#patch_fix">patch fix</a>.</p>
<p>The terms geo-parsing and geo-referencing are used interchangeably in this lesson and refer to the entire process of identifying place names in text (place name recognition) and disambiguating them by assigning their most likely latitude/longitude pairs (geo-resolution).</p>
<p>The Edinburgh Geoparser is used in conjunction with various gazetteers. The term <a href="https://en.wikipedia.org/wiki/Gazetteer">gazetteer</a> here refers to a list of place names and information about them (e.g. their latitude/longitude coordinates, population size and country they are contained in).  More information on <a href="/lessons/extracting-keywords">Using Gazetteers to Extract Sets of Keywords from Free-Flowing Texts</a> can be found in Adam Cryble&#39;s Programming Historian lesson. His lesson focusses on matching gazetteer entries in text to identify place names.  The Edinburgh Geoparser goes beyond string matching as it applies a large number of rules to identify place names and other types of named entities in text and goes on to ground the extracted entities (either by geo-resolution or date normalisation).</p>
<h2 id="downloading-and-setting-up-the-geoparser">Downloading and Setting up the Geoparser</h2>
<p>The current Edinburgh Geoparser download can be found at <a href="https://www.ltg.ed.ac.uk/software/geoparser/">https://www.ltg.ed.ac.uk/software/geoparser/</a>.</p>
<p>Go to the Download section and click on The Edinburgh Geoparser link.  All you need to do then is accept the license, fill in some personal details, and then press <strong>Download</strong>.  A compressed file called <code>geoparser-march2016.tar.gz</code> will be downloaded to your Download directory or to wherever you specified the download to go.  Note that this file name will change new versions of the tool are released.</p>
<p>Some machines will automatically decompress the .gz file and create the directory <code>geoparser-v1.1</code>.  If this happens, and you see the <code>geoparser-v1.1</code> directory appear, move this new directory to wherever you want it to be installed and go to step 2.  If this does not happen, and your machine does not decompress the <code>.tar.gz</code> file and create a new directory automatically, follow step 1 first.  (Note that version 1.1 is the current release but this number will change in the future.)</p>
<h4 id="installation-steps-via-the-gui-interface">Installation Steps via the GUI interface</h4>
<p>1. Go to the download of the Geoparser and move it to the directory of your choice (e.g. into the <code>Software</code> directory).  Then double-click on the <code>.gz</code> or <code>.tar</code> file (if is was already decompressed automatically).  A new directory called <code>geoparser-v1.1</code> will appear (see Figure 1).</p>
<p>{% include figure.html filename=&quot;geoparser_figure11.png&quot; caption=&quot;Figure 1: The new geoparser-v1.1 directory.&quot; %}</p>
<p>If you double-click on the geoparser-v1.1 folder you can see the content of the Geoparser (see Figure 2). That&#39;s it. You&#39;re ready to geo-parse.</p>
<p>{% include figure.html filename=&quot;geoparser_figure00.png&quot; caption=&quot;Figure 2: Content of the Geoparser.&quot; %}</p>
<h3 id="installation-steps-for-the-command-line">Installation Steps for the Command Line</h3>
<p>1. Move (<code>mv</code>) the <code>.tar.gz</code> file to the directory where you want to install the Geoparser.  In this case, I&#39;d like the Geoparser to be installed in my <code>Software</code> directory inside the <code>Documents</code> directory.  If you don’t have a Software directory, create it first:</p>
<pre><code>mkdir ~/Documents/Software
</code></pre>
<p>Then type:</p>
<pre><code>mv ~/Downloads/geoparser-march2016.tar.gz ~/Documents/Software/
</code></pre>
<p>For this lesson it is assumed that the geoparser is now located inside the <code>~/Documents/Software</code> directory.  You may however want to adjust these commands by specifying the place where the Geoparser was downloaded to and a different directory you’d like to install it in. For example if you&#39;d like to create a new directory called <code>geoparsing</code> in your home directory and put the Geoparser there, then you would type:</p>
<pre><code>mkdir ~/geoparsing
mv ~/Downloads/geoparser-march2016.tar.gz ~/geoparsing/
</code></pre>
<p>2. Next, you need to change to the directory containing the <code>geoparser-march2016.tar.gz</code> file so that the following command is local to that directory and you do not have to specify the entire path leading to it.  To do that you use the command <code>cd</code> (change directory), e.g.: </p>
<pre><code>cd ~/Documents/Software/
</code></pre>
<p>3. Run the following command on the command line to decompress the download:</p>
<pre><code>tar -xvf geoparser-march2016.tar.gz
</code></pre>
<p>You should see a long list of files appear on screen that are part of the distribution.  The <code>Software</code> directory will now contain a new directory called <code>geoparser-v1.1</code>.  It contains:</p>
<ul>
<li><code>README:</code> a file with basic instructions for how to run the Geoparser</li>
<li><code>bin:</code> a set of executables, programs to be run by a computer, for different operating systems. There are executables for Linux (x86_64) and MacOSX.</li>
<li><code>in:</code> a directory with example input files</li>
<li><code>lib:</code> a set of libraries required for various processing steps</li>
<li><code>out:</code> a directory with example output files</li>
<li><code>resolve:</code> a directory containing programs required for geo-resolution</li>
<li><code>scripts:</code> a directory with a set of scripts to run the Geoparser</li>
</ul>
<p>You can list (<code>ls</code>) and check its content by typing:</p>
<pre><code>ls ./geoparser-v1.1
</code></pre>
<p>Congratulations! You have successfully downloaded and set up the Geoparser, and you can now begin geo-parsing.</p>
<h2 id="geo-parsing-a-text-file">Geo-parsing a Text File</h2>
<p>In this section you will learn how to geo-parse a simple text file.  Use the <code>cd</code> command to go the geoparser’s script directory:</p>
<pre><code>cd ./geoparser-v1.1/scripts
</code></pre>
<p>and try out one of the examples provided as part of the distribution by running the following two commands:</p>
<pre><code>cat ../in/172172.txt | ./run -t plain -g geonames -o ../out 172172
</code></pre>
<p>Note that if your machine is running macOS Sierra (Darwin 16.7.0) or later versions then you need to apply a temporary <a href="#patch_fix">patch fix</a> as this will give you an error.</p>
<p>For those not so familiar with working on the command line, let&#39;s look at the syntax used here.  Firstly, it is useful to know that the pipe character (<code>|</code>) is used to concatenate different commands.</p>
<p>In the previous example the first command is:</p>
<pre><code>cat ../in/172172.txt
</code></pre>
<p>The command <code>cat</code> prints a file (in this case the file is called <code>172172.txt</code> and it is located in the <code>in</code> directory of the geoparser) to your screen (or to <em>standard out</em> or short <em>stdout</em>).  The pipe character (<code>|</code>) is used to send the standard output of one command to the next command which can then use it as <em>standard in</em> (or short <em>stdin</em>).</p>
<p>The second command is:</p>
<pre><code>./run -t plain -g geonames -o ../out 172172
</code></pre>
<p>It takes the stdout from the first command and runs the Geoparser with the following options (<code>-t</code>, <code>-g</code> and <code>-o</code>):</p>
<ul>
<li><p><code>-t</code> specifies the format of your input.  Text input (<code>plain</code>) is recommended for geo-parsing.</p>
</li>
<li><p><code>-g</code> specifies the gazetteer that should be queried.  In the above example, the gazetteer selected is <a href="http://www.geonames.org/">GeoNames</a> (<code>geonames</code>), a large global gazetteer.  You can also specify other gazetteers, for example the DEEP gazetteer of historical placenames in England (<code>deep</code>) or the Pleiades+ gazetteer of ancient places (<code>plplus</code>).  For more information on the types of gazetteers offered as part of the distribution see the Geoparser documentation <a href="http://groups.inf.ed.ac.uk/geoparser/documentation/v1.1/html/gaz.html">here</a>.</p>
</li>
<li><p><code>-o</code> specifies two pieces of information, the output directory (<code>../out</code>) which is located within the <code>geoparser-v1.1</code> directory and a prefix for the output file name (in this case <code>172172</code>, the same prefix as that of the input file name). Once the command is run and the Geoparser is finished, the result files appear in the output directory (<code>../out</code>) starting with the specified prefix.</p>
</li>
</ul>
<p>When running the Geoparser, the specified text file is going through a series of processing steps which are combined into one pipeline.  It is first <a href="https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization_">tokenised</a>, <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech-tagged</a> and <a href="https://en.wikipedia.org/wiki/Lemmatisation">lemmatised</a>. After these initial steps, <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a> is performed to identify location and person names as well as dates.  It was  found that identifying location and person names in parallel helps to distinguish some ambiguous cases (like the string &quot;Lewis&quot; which could refer to a first name or the Scottish island) and where their context helps to distinguish between them.  The extracted locations are then resolved to latitude/longitude coordinate pairs.  The text is then further processed by identifying syntactic phrases (chunking) and temporal relations.  The latter two steps are not very relevant to this lesson and will therefore not be explained in detail.  Finally, visualisations are created to be able to inspect the file and the Geoparser output using a map interface in a browser.  For more information on each of the sub-components of the Geoparser, see the documentation <a href="http://groups.inf.ed.ac.uk/geoparser/documentation/v1.1/html/pipeline.html">here</a>.</p>
<p>Note that when using the Geoparser in combination with the GeoNames gazetteer some historical place names will not be identified as they are missing from the gazetteer.  Also the Geoparser team can provide additional pre-processing to improve the quality of optical-character recognised output (e.g. to fix soft-hyphen splitting or to deal with the long “s” character).  Those scripts are not distributed with the standard distribution but available on request.</p>
<p>To see the output files, go to the <code>out</code> directory:</p>
<pre><code>cd ../out
</code></pre>
<p>Now you can see all the files that the Geoparser has produced from the original <code>172172.txt</code> file.  Use the <code>ls</code> command and the <code>*</code> wildcard operator to see all the files beginning witht the prefix <code>172172</code>, like so:</p>
<pre><code>ls 172172*

172172.display.html 172172.gazlist.html 172172.nertagged.xml
172172.events.xml 172172.gazmap.html 172172.out.xml
172172.gaz.xml 172172.geotagged.html 172172.timeline.html
</code></pre>
<p>The most relevant Geoparser output files contain the following information:</p>
<ul>
<li><code>172172.out.xml</code>: This is the XML file containing the text of the file in XML including all linguistic processing information specified in line with the text as well as the named entity recognition and the geo-resolution output.  In this file only the top-ranked geo-coordinates per resolved location are stored.  If you are not familiar with XML, looking at this file might be quite daunting. I will explain below how to extract the geo-resolution information to TSV (tab separated values) format.</li>
<li><code>172172.gaz.xml</code>: This is an XML file containing a ranked list of geo-resolution candidates for each extracted location mention.  The gazetteer (e.g. GeoNames) may contain more than one location per location mention and therefore all candidates are listed here.  By default, the number of location candidates returned is capped at 20 if more candidates are present in the gazetteer.  Increasing the number of candidates to be considered by the Geoparser does not increase performance considerably but increases processing time significantly (Alex et al., 2015).</li>
<li><code>172172.display.html</code>: This is a visual display of the geo-parsed text file containing the text, a map and a list of geo-coordinates for each extracted location.</li>
</ul>
<p>You can view <code>172172.display.html</code> in your browser by typing:</p>
<ul>
<li>On MacOSX: <code>open 172172.display.html</code></li>
<li>On Linux:         <code>xdg-open 172172.display.html</code></li>
</ul>
<p>{% include figure.html filename=&quot;geoparser_figure01.png&quot; caption=&quot;Figure 3: Display of file 172172.display.html in a browser.&quot; %}</p>
<p>At the top of the browser window (see Figure 3) you will see a Google map interface with green and red pins.  At the bottom left is a window containing the text of the geo-parsed file with recognised locations highlighted in light green and at the bottom right there is a window containing the different geo-coordinate pairs for all the candidates considered per extracted location mention.  The ones in green are the top-ranked coordinate pairs which correspond to the green pins on the map.  The red pairs are lower ranked alternatives which correspond to the red pins on the map.</p>
<p>You can also specify the option <code>-top</code> on the command line. This creates some additional output files, most notably <code>172172.display-top.html</code> which only contains the top-ranked location candidates, so only the green geo-coordinate pairs and pins are displayed (see Figure 4).</p>
<pre><code>cat ../in/172172.txt | ./run -t plain -g geonames -top -o ../out 172172
</code></pre>
<p>{% include figure.html filename=&quot;geoparser_figure02.png&quot; caption=&quot;4: Display of file 172172.display-top.html in a browser.&quot; %}</p>
<p>The vanilla download works most accurately with running English text.  It even works on individual sentences.  Geo-resolution accuracy increases however if the Geoparser has access to more context.  On the other hand, the Geoparser is not well suited to process large documents made up of several sub-texts, e.g. a journal issue made up of articles. In the latter case it would be better to split the document into the articles first.</p>
<h2 id="other-useful-options-for-running-the-geoparser">Other Useful Options for Running the Geoparser</h2>
<h3 id="giving-preference-to-a-geographical-area">Giving Preference to a Geographical Area</h3>
<p>If you know that your text is about a particular geographical area you can instruct the Geoparser to give this area higher weighting during the geo-resolution step. For example, if you know that your data is mostly set in Canada then it may make sense to give candidate locations inside Canada higher preference.  By doing so the Geoparser will prefer places within the specified area but it will still consider locations outside it if other factors give them higher weighting.</p>
<p>A bounding area can be specified as a circle (<code>-l locality</code>) or a box (<code>-lb locality box</code>).  To specify a circular locality use the following command:</p>
<pre><code>-l lat long radius score
</code></pre>
<p>where:</p>
<ul>
<li><code>lat</code> and <code>long</code> are in decimal degrees (i.e. 57.5 for 57 degrees 30 mins)</li>
<li><code>radius</code> is specified in km</li>
<li><code>score</code> is a numeric weight assigned to locations within the area (else 0).</li>
</ul>
<p>To specify a locality box use:</p>
<pre><code>-lb W N E S score
</code></pre>
<p>where</p>
<ul>
<li><code>W</code>(est) <code>N</code>(orth) <code>E</code>(ast) <code>S</code>(outh) are decimal degrees</li>
<li><code>score</code> is the same as for option <code>-l</code>.</li>
</ul>
<p>You can grab the coordinates of a bounding box for a particular area using this online <a href="http://boundingbox.klokantech.com">BoundingBox</a> tool. For example, a bounding box for Canada is <code>[W:-141.002701, N:83.110619, E:-52.620201, S:41.681019]</code> (see Figure 5)</p>
<p>{% include figure.html filename=&quot;geoparser_figure03.png&quot; caption=&quot;Figure 5: Bounding box for Canada drawn on <a href="http://boundingbox.klokantech.com">BoundingBox</a>.&quot; %}</p>
<p>To specify this bounding box using the previous example, go back to the scripts directory and run the following command:</p>
<pre><code>cat ../in/172172.txt | ./run -t plain -g geonames -lb -141.002701 83.110619 -52.620201 41.681019 2 -o ../out 172172 
</code></pre>
<p>Here, the <code>score</code> has been set to 2.  This gives a location within the bounding box twice as much weight as for example the population size of a location during geo-resolution.</p>
<p>{% include figure.html filename=&quot;geoparser_figure04.png&quot; caption=&quot;Figure 6: Display of file 172172.display.html after geo-parsing with a specified bounding box.&quot; %}</p>
<p>In this case, all place names (including Washington, Wimbledon, Germany and France) were resolved to locations within the bounding box (see Figure 6).  The locality option should therefore be used with care and should ideally only be applied to documents where you are relatively certain that all or most locations appear within the specified area.</p>
<h3 id="specifying-a-document-date">Specifying a Document Date</h3>
<p>As well as identifying locations and person names within text, the Geoparser also recognises temporal expressions (dates and times) in textual data and normalises them. Normalisation here means that the temporal expressions are enriched with additional information of when exactly they occurred. For example, it computes which the exact calendar date the expression &quot;last Friday&quot; refers to.</p>
<p>In order to do this well, it is preferable to provide the Geoparser with the date of the document (if known). To try this out using the previous example, type the following command:</p>
<pre><code>cat ../in/172172.txt | ./run -t plain -g geonames -d 2010-08-10 -o ../out 172172 
</code></pre>
<ul>
<li><code>-d</code> specifies the document date (<code>YEAR-MONTH-DATE</code>).  This option is optional.  It is used for normalisation (or grounding) of temporal expressions in the document, for example to compute which particular calendar date the string “Sunday” refers to.</li>
</ul>
<p>The document date specified on the command line is stored in the XML output and all relative temporal expression will be automatically interpreted with respect to it.  The document date (<code>docdate</code>) is stored in the meta section at the top of the XML output file.  Use the <code>head</code> command to list the first 5 lines of the output file where you can see it:</p>
<pre><code>head -n 5 ../out/172172.out.xml

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;document version=&quot;3&quot;&gt;
&lt;meta&gt;
&lt;attr name=&quot;docdate&quot; id=&quot;docdate&quot; year=&quot;2010&quot; month=&quot;08&quot; date=&quot;10&quot; sdate=&quot;2010-08-10&quot; day-number=&quot;733993&quot; day=&quot;Tuesday&quot; wdaynum=&quot;2&quot;&gt;20100810&lt;/attr&gt;
&lt;attr name=&quot;tokeniser_version&quot; date=&quot;20151216&quot;/&gt;&lt;/meta&gt;
</code></pre>
<p>Using the example output file, the first recognised date string in the named  entity output is “Sunday” which appears in the sentence:</p>
<blockquote>
<p>&quot;Rafael Nadal and Andy Murray are both through to the semifinals of the Rogers Cup in Toronto, where they will face each other for a place in Sunday&#39;s final.&quot;</p>
</blockquote>
<p>Since the document date is Aug 8th 2010 which was a Tuesday, the Sunday referred to in this text is Aug 15th 2010.  The output of the correct temporal resolution for this example can be seen in the entity output in the standoff section of the <code>172172.out.xml</code> file:</p>
<pre><code>&lt;ent date=&quot;15&quot; month=&quot;08&quot; year=&quot;2010&quot; sdate=&quot;2010-08-15&quot; day-number=&quot;733998&quot; id=&quot;rb7&quot; type=&quot;date&quot; day=&quot;Sunday&quot; wdaynum=&quot;7&quot;&gt;
   &lt;parts&gt;
</code></pre>
<p>          <part ew="w204" sw="w204">Sunday</part>
       </parts>
    </ent></p>
<p>Besides the obvious <code>date</code>, <code>month</code>, <code>year</code> and <code>day</code> attributes:</p>
<ul>
<li><code>sdate</code> refers to the grounded date expressed as a string,</li>
<li><code>day-number</code> refers to a unique day number where 1 corresponds to the 1st of January 1 AD, and</li>
<li><code>wdaynum</code> refers to the week day number where 1 corresponds to Monday, 2 to Tuesday etc.</li>
</ul>
<p>This type of normalisation makes it possible to plot the events mentioned in a piece of text on a timeline.  A timeline view is automatically created at the end of each geoparser run. To view the one for our example <code>172172</code>, open the <code>172172.timeline.html</code> file in Firefox (this view is not configured for other browsers at the moment).</p>
<p>On MacOSX:</p>
<pre><code>open -a Firefox ./out/172172.timeline.html
</code></pre>
<p>On Linux:</p>
<pre><code>xdg-open ./out/172172.timeline.html
</code></pre>
<p>{% include figure.html filename=&quot;geoparser_figure12.png&quot; caption=&quot;Figure 7: Timeline view for the example <code>172172</code> displayed in Firefox. You can see that the dates are normalised to the timeline at the bottom of the screen.&quot; %}</p>
<p>Figure 7 is a screenshot of the timeline view in Firefox.  At the top of the screen you can see the text of the example with different entity types (person, location, organisation and temporal expression) marked up in different colours.  Underneath you can see the timeline view with normalised dates and their events pinned to the calendar.</p>
<p>If the document date is not specified all temporal expressions will be interpreted relative to the date when the Geoparser is run.  While this setting does not affect the performance of the geo-resolution of place names in this release, one could imagine a possible extension where the document date affects the type of gazetteer used or the location name variants that should be considered as place names change over time.</p>
<h3 id="geo-parsing-multiple-text-files">Geo-parsing Multiple Text Files</h3>
<p>Now that you know how to geo-parse one file, you may want to do the same thing for a set of documents all at once. You can download a simple shell script which geo-parses multiple files <a href="http://groups.inf.ed.ac.uk/geoparser/scripts/run-multiple-files.sh">here</a>. Please refer to the <a href="http://homepages.inf.ed.ac.uk/balex/publications/geoparser-workshop.pdf">Geoparser workshop</a> slides for more information on how to make this script executable, run and it and adapt it to your needs.</p>
<h3 id="extracting-geo-resolution-output-to-tsv">Extracting Geo-Resolution Output to TSV</h3>
<p>The output of the Geoparser is in XML format. This is useful as XML can store various types of information present in text along with it.  For example, it can store low-level information like the boundaries of words, their part-of-speech tags and lemmas.  It can also store more complex information like phrases and entities occurring in the text as well as links between them, for example the subject and object of a sentence or the location (e.g. birthplace) of a person.  The advantage is that all the computed structural and linguistic information computed for a piece of text is stored along with it and downstream natural language processing tools have all the information available.</p>
<p>While XML is easy to process by a machine it is difficult to read by human readers. You may also not be interested in all the information computed by the Geoparser and might only want to see which locations were identified along with their coordinates. So rather than dealing with an XML file, you might find it easier to work with the Geoparser output in a form such as tab-separated values (TSV) in order to inspect it in a spreadsheet or use it with an application such as QGIS or Google Maps/Google Earth for which there are already useful Programming Historian lessons available (<a href="/lessons/qgis-layers">Installing QGIS 2.0 and Adding Layers</a> and <a href="/lessons/googlemaps-googleearth">Intro to Google Maps and Google Earth</a>).</p>
<p>The Geoparser is distributed with a useful set of XML processing tools called <a href="https://www.ltg.ed.ac.uk/software/ltxml2/">LT-XML2</a>, authored by Richard Tobin, which can be used to extract the location entities in a Geoparser XML output file and to present them in tab-separated value (TSV) format. The executables for these tools are located in the <code>./geoparser/bin</code> directory, inside:</p>
<ul>
<li><code>sys-i386-64</code>: if you are using a 64 bit Linux machine or</li>
<li><code>sys-i386-snow-leopard</code>: if you’re using MacOSX.  Don’t be confused by the name of this directory.  The executables should work for all MacOSX installations and not just on Snow Leopard.</li>
</ul>
<p>All the executables starting with <em>lx</em> are LT-XML tools which work in combination with Xpath expressions to process or manipulate XML.  Going in detail over Xpath is beyond the scope of this lesson, so I will give clear examples to show how things work.  If you are interested in XML data manipulation you will find further detail in <a href="/lessons/transforming-xml-with-xsl">Transforming Data for Reuse and Re-publication</a>.</p>
<p>The best tool for printing XML content in a different format is <code>lxprintf</code>. Depending on your operating system, go to the <code>geoparser</code> directory and run <code>lxprintf</code> as follows:</p>
<p>On Linux use:</p>
<pre><code>./bin/sys-i386-64/lxprintf -e &quot;ent[@type=&#39;location&#39;]&quot; &quot;%s\t%s\t%s\t%s\t%s\n&quot; &quot;normalize-space(parts/part)&quot; &quot;@gazref&quot; &quot;@in-country&quot; &quot;@lat&quot; &quot;@long&quot; &lt; ./out/172172.out.xml&gt; ./out/172172.out.tsv
</code></pre>
<p>and on MacOSX type:</p>
<pre><code>./bin/sys-i386-snow-leopard/lxprintf -e &quot;ent[@type=&#39;location&#39;]&quot; &quot;%s\t%s\t%s\t%s\t%s\n&quot; &quot;normalize-space(parts/part)&quot; &quot;@gazref&quot; &quot;@in-country&quot; &quot;@lat&quot; &quot;@long&quot; &lt; ./out/172172.out.xml&gt; ./out/172172.out.tsv
</code></pre>
<p>The previous <code>lxprintf</code> command reads through a geo-parsed XML output file, extracts all location entities identified by the Geoparser and presents them in TSV format. In the example above, the XML input file (containing the location entities) is <code>./out/172172.out.xml</code>, and the TSV file is <code>./out/172172.out.tsv</code>. The <code>&lt;</code> symbol signifies &quot;standard in&quot; (or stdin) which tells the script to read in the file that follows it and the <code>&gt;</code> symbol signifies standard out (or stdout) which specifies sending the output to the file that follows it.</p>
<p>The way this command works is that lxprintf looks for XML entities specified after the option <code>-e</code>.  In this case, entities of type location are to be extracted (<code>&quot;ent[@type=&#39;location’]”</code>).  Here is an example of an entity of type location in the XML:</p>
<pre><code>&lt;ent id=&quot;rb6&quot; type=&quot;location&quot; lat=&quot;43.70011&quot; long=&quot;-79.4163&quot; gazref=&quot;geonames:6167865&quot; in-country=&quot;CA&quot; feat-type=&quot;ppla&quot; pop-size=&quot;4612191&quot;&gt;
  &lt;parts&gt;
    &lt;part ew=&quot;w148&quot; sw=&quot;w148&quot;&gt;Toronto&lt;/part&gt;
  &lt;/parts&gt;
&lt;/ent&gt;
</code></pre>
<p>The next part of the command (<code>“%s\t%s\t%s\t%s\t%s\n”</code>) specifies how the output should be printed.  In this case, each specified string (<code>%s</code>) is delimited by a tab (<code>\t</code>) character and the last string is followed by a new line.  In this case, the following 5 strings for each location entity are specified:</p>
<ul>
<li><code>&quot;normalize-space(parts)&quot;</code> refers to the location mention recognised in the text. normalize() removes any unnecessary whitespace.</li>
<li><code>&quot;@gazref”</code> refers to the ID reference of the location in the gazetteer, if resolved.</li>
<li><code>&quot;@in-country”</code> refers to the country the location appears in, if this information was identified.</li>
<li><code>&quot;@lat”</code> refers to the latitude of the location, if this information was identified.</li>
<li><code>&quot;@long”</code> refers to the longitude of the location, if this information was identified.</li>
</ul>
<p>When printed to screen, the content of the TSV output file is therefore the following:</p>
<pre><code>cat ./out/172172.out.tsv

Toronto geonames:6167865        CA      43.70011        -79.4163
Germany geonames:2921044        DE      51.5    10.5
Washington      geonames:4140963        US      38.89511        -77.03637
Montreal        geonames:6077243        CA      45.50884        -73.58781
Wimbledon       geonames:4668339        US      35.71814        -83.97907
France  geonames:3017382        FR      46      2
</code></pre>
<p>If you open <code>./out/172172.out.tsv</code> in Excel, for example, you can see that the information is now presented in column format, in this case listing the place name, the GeoNames ID, the country code, the latitude and the longitude (see Figure 8).</p>
<p>{% include figure.html filename=&quot;geoparser_figure10.png&quot; caption=&quot;Figure 8: Geo-parsed location information from the example <code>172172</code> displayed in Excel.&quot; %}</p>
<p>Once you have extracted the geo-location information from the <code>*out.xml</code> file(s) you can use it as input into your favourite mapping tool though you will have to adjust the format depending on your needs.</p>
<p><a name="patch_fix"></a></p>
<h2 id="patch-fix">Patch Fix</h2>
<p>If your machine is running maxOS Sierra (Darwin 16.7.0) or later versions you will get an error message similar to the following when running the Geoparser version 1.1:</p>
<pre><code>unrecognised platform Darwin 16.7.0 x86_64
edit scripts/setup, or set LXPATH to appropriate path
</code></pre>
<p>You need to apply the following patch fix to get it to work properly. Open the <code>setup</code> file in the <code>scripts</code> directory with your favourite editor and replace the following line:</p>
<p>  <code>Darwin?1[012345]*)</code></p>
<p>with</p>
<p>  <code>Darwin?1[0-9]*)</code></p>
<p>We will release a new version shortly which will fix is this error.</p>
<h2 id="credits-and-citation">Credits and Citation</h2>
<p>The Geoparser and its demo were developed over a number of years in a team effort by members of the <a href="https://www.ltg.ed.ac.uk/">Edinburgh Language Technology Group</a>, including Claire Grover, Richard Tobin, Kate Byrne and myself (Beatrice Alex).</p>
<p>If you found this lesson useful for your work, please cite it as:</p>
<pre><code>Beatrice Alex. 2017. Geoparsing Text with the Edinburgh Geoparser, The Programming Historian lesson, /lessons/geoparsing-text-with-edinburgh, 2017.
</code></pre>
<p>or cite one of the publications listed <a href="https://www.ltg.ed.ac.uk/software/geoparser/">here</a>.</p>
<p>The lesson is also available in workshop form.  If you&#39;re interested in running a workshop on how to use the Edinburgh Geoparser, do get in touch.</p>
<p>The Geoparser team also welcomes suggestions for future collaboration to tailor the Geoparser to different needs.  Please get in touch if you have ideas about how it could be applied.</p>
<p>In the past the Geoparser was used to identify place names for different purposes and in different types of data (e.g. Grover et al., 2010 and Alex et al., 2015).  For example, it was adapted to perform fine-grained geo-parsing for literature set in Edinburgh (<a href="http://palimpsest.blogs.edina.ac.uk/">Palimpsest</a>) presented in the <a href="http://litlong.org/">LitLong</a> interface.  It was used to geo-parse</p>
<ul>
<li>volumes of the Survey of English Place Names (<a href="http://web.archive.org/web/20170722115758/http://englishplacenames.cerch.kcl.ac.uk/">DEEP</a>, see Grover and Tobin, 2014),</li>
<li>large historical collections related to commodity trading in the 19th century British Empire (<a href="http://tradingconsequences.blogs.edina.ac.uk/">Trading Consequences</a>) and</li>
<li>19th century British newspapers by <a href="http://www.lancaster.ac.uk/staff/gregoryi/">Prof. Ian Gregory</a>’s group at Lancaster University.</li>
</ul>
<p>The Geoparser was also adapted to the ancient world for the <a href="https://googleancientplaces.wordpress.com/">Google Ancient Places</a> project (e.g. see Isaksen et al., 2011), with its <a href="http://nrabinowitz.github.io/gapvis/">GapVis</a>  interface. More recently, the Geoparser was used to geo-parse Twitter user profile locations (Alex et al, 2016).</p>
<h2 id="references">References</h2>
<p>Beatrice Alex, Clare Llewellyn, Claire Grover, Jon Oberlander and Richard Tobin (2016). Homing in on Twitter users: Evaluating an Enhanced Geoparser for User Profile Locations. 2016. In the Proceedings of the 10th Language Resources and Evaluation Conference (LREC), 23-28 May 2016. [<a href="http://www.lrec-conf.org/proceedings/lrec2016/pdf/129_Paper.pdf">pdf</a>]</p>
<p>Beatrice Alex, Kate Byrne, Claire Grover and Richard Tobin (2015). Adapting the Edinburgh Geoparser for Historical Georeferencing. International Journal for Humanities and Arts Computing, 9(1), pp. 15-35, March 2015.[<a href="http://www.euppublishing.com/doi/pdfplus/10.3366/ijhac.2015.0136">pdf</a>]</p>
<p>Claire Grover and Richard Tobin (2014). A Gazetteer and Georeferencing for Historical English Documents. In Proceedings of LaTeCH 2014 at EACL 2014. Gothenburg, Sweden. <a href="http://www.aclweb.org/anthology/W14-0617">[pdf]</a></p>
<p>Claire Grover, Richard Tobin, Kate Byrne, Matthew Woollard, James Reid, Stuart Dunn, and Julian Ball (2010). Use of the Edinburgh Geoparser for georeferencing digitised historical collections. Philosophical Transactions of the Royal Society A. [<a href="http://homepages.inf.ed.ac.uk/grover/papers/PTRS-A-2010-Grover-3875-89.pdf">pdf</a>]</p>
<p>Leif Isaksen, Elton Barker, Eric C. Kansa, Kate Byrne (2012). GAP: A NeoGeo Approach to Classical Resources. Leonardo 45 (1): 82–83. [<a href="https://direct.mit.edu/leon/article/45/1/82/46956/GAP-A-NeoGeo-Approach-to-Classical-Resources#.U48IuXWx15Q">pdf</a>]</p>
<!-- HTML_TAG_END -->

<script type="application/json" data-type="svelte-data" data-url="geoparsing-text-with-edinburgh/raw.json">{"status":200,"statusText":"","headers":{"content-type":"application/json; charset=utf-8"},"body":"{\"metadata\":{\"title\":\"Geoparsing English-Language Text with the Edinburgh Geoparser\",\"collection\":\"lessons\",\"layout\":\"lesson\",\"slug\":\"geoparsing-text-with-edinburgh\",\"date\":\"2017-10-31T00:00:00.000Z\",\"authors\":[\"Beatrice Alex\"],\"reviewers\":[\"Anouk Lang\",\"Sarah Simpkin\"],\"editors\":[\"Ian Milligan\"],\"difficulty\":3,\"review-ticket\":\"https:\u002F\u002Fgithub.com\u002Fprogramminghistorian\u002Fph-submissions\u002Fissues\u002F26\",\"activity\":\"presenting\",\"topics\":[\"mapping\"],\"abstract\":\"This tutorial teaches users how to use the Edinburgh Geoparser to process a piece of English-language text, extract and resolve the locations contained within it, and plot them as a web map.\",\"redirect_from\":\"\u002Flessons\u002Fgeoparsing-text-with-edinburgh\",\"avatar_alt\":\"Map of the city of Edinburgh\",\"doi\":\"10.46430\u002Fphen0067\"},\"html_body\":\"\u003Cp\u003E{% include toc.html %}\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"introduction\\\"\u003EIntroduction\u003C\u002Fh2\u003E\\n\u003Cp\u003EThis is a lesson on how to use the \u003Ca href=\\\"https:\u002F\u002Fwww.ltg.ed.ac.uk\u002Fsoftware\u002Fgeoparser\u002F\\\"\u003EEdinburgh Geoparser\u003C\u002Fa\u003E.  The Geoparser allows you to process a piece of English-language text and extract and resolve the locations contained within it. Among other uses, geo-resolution of locations makes it possible to map the data.\u003C\u002Fp\u003E\\n\u003Cp\u003EThe Geoparser works best on running text, as it considers locations in context for disambiguation. For example, if you would like to get a sense of the place names mentioned in a piece of text, the Geoparser can be used to identify terms in a document that are likely to refer to place names.  It will then provide its best guess as to where those places are in terms of latitute\u002Flongitude coordinates.\u003C\u002Fp\u003E\\n\u003Cp\u003EIn December 2015, the Edinburgh Geoparser was released under the University of Edinburgh’s GPL license to be used by other researchers in the field of text mining as well as other scholars who are interested in geoparsing text. More information on its documentation, publications about it and how to download it can be found \u003Ca href=\\\"https:\u002F\u002Fwww.ltg.ed.ac.uk\u002Fsoftware\u002Fgeoparser\u002F\\\"\u003Ehere\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\\n\u003Cp\u003EA simple online demo of the vanilla Edinburgh Geoparser can be tried out \u003Ca href=\\\"http:\u002F\u002Fjekyll.inf.ed.ac.uk\u002Fgeoparser.html\\\"\u003Ehere\u003C\u002Fa\u003E. It provides only the visual interface to the Geoparser output after uploading a text file and selecting a gazetteer.  The demo is otherwise not configurable and should only be used to try out small examples and not for geo-parsing a large number of files.\u003C\u002Fp\u003E\\n\u003Cp\u003EThe following lesson explains how the Edinburgh Geoparser works under the hood and contains information on:\u003C\u002Fp\u003E\\n\u003Cul\u003E\\n\u003Cli\u003EPrerequisites and terminology\u003C\u002Fli\u003E\\n\u003Cli\u003EDownloading and setting up the Edinbugh Geoparser,\u003C\u002Fli\u003E\\n\u003Cli\u003EGeo-parsing a text file,\u003C\u002Fli\u003E\\n\u003Cli\u003EOther useful options for running the Geoparser,\u003C\u002Fli\u003E\\n\u003Cli\u003EGeo-parsing multiple text files, and\u003C\u002Fli\u003E\\n\u003Cli\u003EExtracting geo-resolution output to TSV.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003Ch2 id=\\\"prerequisites-and-terminology\\\"\u003EPrerequisites and Terminology\u003C\u002Fh2\u003E\\n\u003Cp\u003EThis lesson requires users to be familiar with the command line.  If not then you should follow the lesson \u003Ca href=\\\"\u002Flessons\u002Fintro-to-bash\\\"\u003EIntroduction to the Bash Command Line\u003C\u002Fa\u003E first.\u003C\u002Fp\u003E\\n\u003Cp\u003EThe Geoparser works on MacOS or Linux but is not supported for Windows. The following lesson provides command line instructions for MacOSX users and equivalent commands for Linux users (only if different to the Mac versions). Note that if your machine is running macOS Sierra (Darwin 16.7.0) or later versions then you need to apply a temporary \u003Ca href=\\\"#patch_fix\\\"\u003Epatch fix\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\\n\u003Cp\u003EThe terms geo-parsing and geo-referencing are used interchangeably in this lesson and refer to the entire process of identifying place names in text (place name recognition) and disambiguating them by assigning their most likely latitude\u002Flongitude pairs (geo-resolution).\u003C\u002Fp\u003E\\n\u003Cp\u003EThe Edinburgh Geoparser is used in conjunction with various gazetteers. The term \u003Ca href=\\\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FGazetteer\\\"\u003Egazetteer\u003C\u002Fa\u003E here refers to a list of place names and information about them (e.g. their latitude\u002Flongitude coordinates, population size and country they are contained in).  More information on \u003Ca href=\\\"\u002Flessons\u002Fextracting-keywords\\\"\u003EUsing Gazetteers to Extract Sets of Keywords from Free-Flowing Texts\u003C\u002Fa\u003E can be found in Adam Cryble&#39;s Programming Historian lesson. His lesson focusses on matching gazetteer entries in text to identify place names.  The Edinburgh Geoparser goes beyond string matching as it applies a large number of rules to identify place names and other types of named entities in text and goes on to ground the extracted entities (either by geo-resolution or date normalisation).\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"downloading-and-setting-up-the-geoparser\\\"\u003EDownloading and Setting up the Geoparser\u003C\u002Fh2\u003E\\n\u003Cp\u003EThe current Edinburgh Geoparser download can be found at \u003Ca href=\\\"https:\u002F\u002Fwww.ltg.ed.ac.uk\u002Fsoftware\u002Fgeoparser\u002F\\\"\u003Ehttps:\u002F\u002Fwww.ltg.ed.ac.uk\u002Fsoftware\u002Fgeoparser\u002F\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\\n\u003Cp\u003EGo to the Download section and click on The Edinburgh Geoparser link.  All you need to do then is accept the license, fill in some personal details, and then press \u003Cstrong\u003EDownload\u003C\u002Fstrong\u003E.  A compressed file called \u003Ccode\u003Egeoparser-march2016.tar.gz\u003C\u002Fcode\u003E will be downloaded to your Download directory or to wherever you specified the download to go.  Note that this file name will change new versions of the tool are released.\u003C\u002Fp\u003E\\n\u003Cp\u003ESome machines will automatically decompress the .gz file and create the directory \u003Ccode\u003Egeoparser-v1.1\u003C\u002Fcode\u003E.  If this happens, and you see the \u003Ccode\u003Egeoparser-v1.1\u003C\u002Fcode\u003E directory appear, move this new directory to wherever you want it to be installed and go to step 2.  If this does not happen, and your machine does not decompress the \u003Ccode\u003E.tar.gz\u003C\u002Fcode\u003E file and create a new directory automatically, follow step 1 first.  (Note that version 1.1 is the current release but this number will change in the future.)\u003C\u002Fp\u003E\\n\u003Ch4 id=\\\"installation-steps-via-the-gui-interface\\\"\u003EInstallation Steps via the GUI interface\u003C\u002Fh4\u003E\\n\u003Cp\u003E1. Go to the download of the Geoparser and move it to the directory of your choice (e.g. into the \u003Ccode\u003ESoftware\u003C\u002Fcode\u003E directory).  Then double-click on the \u003Ccode\u003E.gz\u003C\u002Fcode\u003E or \u003Ccode\u003E.tar\u003C\u002Fcode\u003E file (if is was already decompressed automatically).  A new directory called \u003Ccode\u003Egeoparser-v1.1\u003C\u002Fcode\u003E will appear (see Figure 1).\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;geoparser_figure11.png&quot; caption=&quot;Figure 1: The new geoparser-v1.1 directory.&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003EIf you double-click on the geoparser-v1.1 folder you can see the content of the Geoparser (see Figure 2). That&#39;s it. You&#39;re ready to geo-parse.\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;geoparser_figure00.png&quot; caption=&quot;Figure 2: Content of the Geoparser.&quot; %}\u003C\u002Fp\u003E\\n\u003Ch3 id=\\\"installation-steps-for-the-command-line\\\"\u003EInstallation Steps for the Command Line\u003C\u002Fh3\u003E\\n\u003Cp\u003E1. Move (\u003Ccode\u003Emv\u003C\u002Fcode\u003E) the \u003Ccode\u003E.tar.gz\u003C\u002Fcode\u003E file to the directory where you want to install the Geoparser.  In this case, I&#39;d like the Geoparser to be installed in my \u003Ccode\u003ESoftware\u003C\u002Fcode\u003E directory inside the \u003Ccode\u003EDocuments\u003C\u002Fcode\u003E directory.  If you don’t have a Software directory, create it first:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Emkdir ~\u002FDocuments\u002FSoftware\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003EThen type:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Emv ~\u002FDownloads\u002Fgeoparser-march2016.tar.gz ~\u002FDocuments\u002FSoftware\u002F\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003EFor this lesson it is assumed that the geoparser is now located inside the \u003Ccode\u003E~\u002FDocuments\u002FSoftware\u003C\u002Fcode\u003E directory.  You may however want to adjust these commands by specifying the place where the Geoparser was downloaded to and a different directory you’d like to install it in. For example if you&#39;d like to create a new directory called \u003Ccode\u003Egeoparsing\u003C\u002Fcode\u003E in your home directory and put the Geoparser there, then you would type:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Emkdir ~\u002Fgeoparsing\\nmv ~\u002FDownloads\u002Fgeoparser-march2016.tar.gz ~\u002Fgeoparsing\u002F\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003E2. Next, you need to change to the directory containing the \u003Ccode\u003Egeoparser-march2016.tar.gz\u003C\u002Fcode\u003E file so that the following command is local to that directory and you do not have to specify the entire path leading to it.  To do that you use the command \u003Ccode\u003Ecd\u003C\u002Fcode\u003E (change directory), e.g.: \u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Ecd ~\u002FDocuments\u002FSoftware\u002F\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003E3. Run the following command on the command line to decompress the download:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Etar -xvf geoparser-march2016.tar.gz\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003EYou should see a long list of files appear on screen that are part of the distribution.  The \u003Ccode\u003ESoftware\u003C\u002Fcode\u003E directory will now contain a new directory called \u003Ccode\u003Egeoparser-v1.1\u003C\u002Fcode\u003E.  It contains:\u003C\u002Fp\u003E\\n\u003Cul\u003E\\n\u003Cli\u003E\u003Ccode\u003EREADME:\u003C\u002Fcode\u003E a file with basic instructions for how to run the Geoparser\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003Ebin:\u003C\u002Fcode\u003E a set of executables, programs to be run by a computer, for different operating systems. There are executables for Linux (x86_64) and MacOSX.\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003Ein:\u003C\u002Fcode\u003E a directory with example input files\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003Elib:\u003C\u002Fcode\u003E a set of libraries required for various processing steps\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003Eout:\u003C\u002Fcode\u003E a directory with example output files\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003Eresolve:\u003C\u002Fcode\u003E a directory containing programs required for geo-resolution\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003Escripts:\u003C\u002Fcode\u003E a directory with a set of scripts to run the Geoparser\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003Cp\u003EYou can list (\u003Ccode\u003Els\u003C\u002Fcode\u003E) and check its content by typing:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Els .\u002Fgeoparser-v1.1\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003ECongratulations! You have successfully downloaded and set up the Geoparser, and you can now begin geo-parsing.\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"geo-parsing-a-text-file\\\"\u003EGeo-parsing a Text File\u003C\u002Fh2\u003E\\n\u003Cp\u003EIn this section you will learn how to geo-parse a simple text file.  Use the \u003Ccode\u003Ecd\u003C\u002Fcode\u003E command to go the geoparser’s script directory:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Ecd .\u002Fgeoparser-v1.1\u002Fscripts\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003Eand try out one of the examples provided as part of the distribution by running the following two commands:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Ecat ..\u002Fin\u002F172172.txt | .\u002Frun -t plain -g geonames -o ..\u002Fout 172172\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003ENote that if your machine is running macOS Sierra (Darwin 16.7.0) or later versions then you need to apply a temporary \u003Ca href=\\\"#patch_fix\\\"\u003Epatch fix\u003C\u002Fa\u003E as this will give you an error.\u003C\u002Fp\u003E\\n\u003Cp\u003EFor those not so familiar with working on the command line, let&#39;s look at the syntax used here.  Firstly, it is useful to know that the pipe character (\u003Ccode\u003E|\u003C\u002Fcode\u003E) is used to concatenate different commands.\u003C\u002Fp\u003E\\n\u003Cp\u003EIn the previous example the first command is:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Ecat ..\u002Fin\u002F172172.txt\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003EThe command \u003Ccode\u003Ecat\u003C\u002Fcode\u003E prints a file (in this case the file is called \u003Ccode\u003E172172.txt\u003C\u002Fcode\u003E and it is located in the \u003Ccode\u003Ein\u003C\u002Fcode\u003E directory of the geoparser) to your screen (or to \u003Cem\u003Estandard out\u003C\u002Fem\u003E or short \u003Cem\u003Estdout\u003C\u002Fem\u003E).  The pipe character (\u003Ccode\u003E|\u003C\u002Fcode\u003E) is used to send the standard output of one command to the next command which can then use it as \u003Cem\u003Estandard in\u003C\u002Fem\u003E (or short \u003Cem\u003Estdin\u003C\u002Fem\u003E).\u003C\u002Fp\u003E\\n\u003Cp\u003EThe second command is:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003E.\u002Frun -t plain -g geonames -o ..\u002Fout 172172\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003EIt takes the stdout from the first command and runs the Geoparser with the following options (\u003Ccode\u003E-t\u003C\u002Fcode\u003E, \u003Ccode\u003E-g\u003C\u002Fcode\u003E and \u003Ccode\u003E-o\u003C\u002Fcode\u003E):\u003C\u002Fp\u003E\\n\u003Cul\u003E\\n\u003Cli\u003E\u003Cp\u003E\u003Ccode\u003E-t\u003C\u002Fcode\u003E specifies the format of your input.  Text input (\u003Ccode\u003Eplain\u003C\u002Fcode\u003E) is recommended for geo-parsing.\u003C\u002Fp\u003E\\n\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Cp\u003E\u003Ccode\u003E-g\u003C\u002Fcode\u003E specifies the gazetteer that should be queried.  In the above example, the gazetteer selected is \u003Ca href=\\\"http:\u002F\u002Fwww.geonames.org\u002F\\\"\u003EGeoNames\u003C\u002Fa\u003E (\u003Ccode\u003Egeonames\u003C\u002Fcode\u003E), a large global gazetteer.  You can also specify other gazetteers, for example the DEEP gazetteer of historical placenames in England (\u003Ccode\u003Edeep\u003C\u002Fcode\u003E) or the Pleiades+ gazetteer of ancient places (\u003Ccode\u003Eplplus\u003C\u002Fcode\u003E).  For more information on the types of gazetteers offered as part of the distribution see the Geoparser documentation \u003Ca href=\\\"http:\u002F\u002Fgroups.inf.ed.ac.uk\u002Fgeoparser\u002Fdocumentation\u002Fv1.1\u002Fhtml\u002Fgaz.html\\\"\u003Ehere\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\\n\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Cp\u003E\u003Ccode\u003E-o\u003C\u002Fcode\u003E specifies two pieces of information, the output directory (\u003Ccode\u003E..\u002Fout\u003C\u002Fcode\u003E) which is located within the \u003Ccode\u003Egeoparser-v1.1\u003C\u002Fcode\u003E directory and a prefix for the output file name (in this case \u003Ccode\u003E172172\u003C\u002Fcode\u003E, the same prefix as that of the input file name). Once the command is run and the Geoparser is finished, the result files appear in the output directory (\u003Ccode\u003E..\u002Fout\u003C\u002Fcode\u003E) starting with the specified prefix.\u003C\u002Fp\u003E\\n\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003Cp\u003EWhen running the Geoparser, the specified text file is going through a series of processing steps which are combined into one pipeline.  It is first \u003Ca href=\\\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FLexical_analysis#Tokenization_\\\"\u003Etokenised\u003C\u002Fa\u003E, \u003Ca href=\\\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FPart-of-speech_tagging\\\"\u003Epart-of-speech-tagged\u003C\u002Fa\u003E and \u003Ca href=\\\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FLemmatisation\\\"\u003Elemmatised\u003C\u002Fa\u003E. After these initial steps, \u003Ca href=\\\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FNamed-entity_recognition\\\"\u003Enamed entity recognition\u003C\u002Fa\u003E is performed to identify location and person names as well as dates.  It was  found that identifying location and person names in parallel helps to distinguish some ambiguous cases (like the string &quot;Lewis&quot; which could refer to a first name or the Scottish island) and where their context helps to distinguish between them.  The extracted locations are then resolved to latitude\u002Flongitude coordinate pairs.  The text is then further processed by identifying syntactic phrases (chunking) and temporal relations.  The latter two steps are not very relevant to this lesson and will therefore not be explained in detail.  Finally, visualisations are created to be able to inspect the file and the Geoparser output using a map interface in a browser.  For more information on each of the sub-components of the Geoparser, see the documentation \u003Ca href=\\\"http:\u002F\u002Fgroups.inf.ed.ac.uk\u002Fgeoparser\u002Fdocumentation\u002Fv1.1\u002Fhtml\u002Fpipeline.html\\\"\u003Ehere\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\\n\u003Cp\u003ENote that when using the Geoparser in combination with the GeoNames gazetteer some historical place names will not be identified as they are missing from the gazetteer.  Also the Geoparser team can provide additional pre-processing to improve the quality of optical-character recognised output (e.g. to fix soft-hyphen splitting or to deal with the long “s” character).  Those scripts are not distributed with the standard distribution but available on request.\u003C\u002Fp\u003E\\n\u003Cp\u003ETo see the output files, go to the \u003Ccode\u003Eout\u003C\u002Fcode\u003E directory:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Ecd ..\u002Fout\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003ENow you can see all the files that the Geoparser has produced from the original \u003Ccode\u003E172172.txt\u003C\u002Fcode\u003E file.  Use the \u003Ccode\u003Els\u003C\u002Fcode\u003E command and the \u003Ccode\u003E*\u003C\u002Fcode\u003E wildcard operator to see all the files beginning witht the prefix \u003Ccode\u003E172172\u003C\u002Fcode\u003E, like so:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Els 172172*\\n\\n172172.display.html 172172.gazlist.html 172172.nertagged.xml\\n172172.events.xml 172172.gazmap.html 172172.out.xml\\n172172.gaz.xml 172172.geotagged.html 172172.timeline.html\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003EThe most relevant Geoparser output files contain the following information:\u003C\u002Fp\u003E\\n\u003Cul\u003E\\n\u003Cli\u003E\u003Ccode\u003E172172.out.xml\u003C\u002Fcode\u003E: This is the XML file containing the text of the file in XML including all linguistic processing information specified in line with the text as well as the named entity recognition and the geo-resolution output.  In this file only the top-ranked geo-coordinates per resolved location are stored.  If you are not familiar with XML, looking at this file might be quite daunting. I will explain below how to extract the geo-resolution information to TSV (tab separated values) format.\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003E172172.gaz.xml\u003C\u002Fcode\u003E: This is an XML file containing a ranked list of geo-resolution candidates for each extracted location mention.  The gazetteer (e.g. GeoNames) may contain more than one location per location mention and therefore all candidates are listed here.  By default, the number of location candidates returned is capped at 20 if more candidates are present in the gazetteer.  Increasing the number of candidates to be considered by the Geoparser does not increase performance considerably but increases processing time significantly (Alex et al., 2015).\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003E172172.display.html\u003C\u002Fcode\u003E: This is a visual display of the geo-parsed text file containing the text, a map and a list of geo-coordinates for each extracted location.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003Cp\u003EYou can view \u003Ccode\u003E172172.display.html\u003C\u002Fcode\u003E in your browser by typing:\u003C\u002Fp\u003E\\n\u003Cul\u003E\\n\u003Cli\u003EOn MacOSX: \u003Ccode\u003Eopen 172172.display.html\u003C\u002Fcode\u003E\u003C\u002Fli\u003E\\n\u003Cli\u003EOn Linux:         \u003Ccode\u003Exdg-open 172172.display.html\u003C\u002Fcode\u003E\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;geoparser_figure01.png&quot; caption=&quot;Figure 3: Display of file 172172.display.html in a browser.&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003EAt the top of the browser window (see Figure 3) you will see a Google map interface with green and red pins.  At the bottom left is a window containing the text of the geo-parsed file with recognised locations highlighted in light green and at the bottom right there is a window containing the different geo-coordinate pairs for all the candidates considered per extracted location mention.  The ones in green are the top-ranked coordinate pairs which correspond to the green pins on the map.  The red pairs are lower ranked alternatives which correspond to the red pins on the map.\u003C\u002Fp\u003E\\n\u003Cp\u003EYou can also specify the option \u003Ccode\u003E-top\u003C\u002Fcode\u003E on the command line. This creates some additional output files, most notably \u003Ccode\u003E172172.display-top.html\u003C\u002Fcode\u003E which only contains the top-ranked location candidates, so only the green geo-coordinate pairs and pins are displayed (see Figure 4).\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Ecat ..\u002Fin\u002F172172.txt | .\u002Frun -t plain -g geonames -top -o ..\u002Fout 172172\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;geoparser_figure02.png&quot; caption=&quot;4: Display of file 172172.display-top.html in a browser.&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003EThe vanilla download works most accurately with running English text.  It even works on individual sentences.  Geo-resolution accuracy increases however if the Geoparser has access to more context.  On the other hand, the Geoparser is not well suited to process large documents made up of several sub-texts, e.g. a journal issue made up of articles. In the latter case it would be better to split the document into the articles first.\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"other-useful-options-for-running-the-geoparser\\\"\u003EOther Useful Options for Running the Geoparser\u003C\u002Fh2\u003E\\n\u003Ch3 id=\\\"giving-preference-to-a-geographical-area\\\"\u003EGiving Preference to a Geographical Area\u003C\u002Fh3\u003E\\n\u003Cp\u003EIf you know that your text is about a particular geographical area you can instruct the Geoparser to give this area higher weighting during the geo-resolution step. For example, if you know that your data is mostly set in Canada then it may make sense to give candidate locations inside Canada higher preference.  By doing so the Geoparser will prefer places within the specified area but it will still consider locations outside it if other factors give them higher weighting.\u003C\u002Fp\u003E\\n\u003Cp\u003EA bounding area can be specified as a circle (\u003Ccode\u003E-l locality\u003C\u002Fcode\u003E) or a box (\u003Ccode\u003E-lb locality box\u003C\u002Fcode\u003E).  To specify a circular locality use the following command:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003E-l lat long radius score\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003Ewhere:\u003C\u002Fp\u003E\\n\u003Cul\u003E\\n\u003Cli\u003E\u003Ccode\u003Elat\u003C\u002Fcode\u003E and \u003Ccode\u003Elong\u003C\u002Fcode\u003E are in decimal degrees (i.e. 57.5 for 57 degrees 30 mins)\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003Eradius\u003C\u002Fcode\u003E is specified in km\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003Escore\u003C\u002Fcode\u003E is a numeric weight assigned to locations within the area (else 0).\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003Cp\u003ETo specify a locality box use:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003E-lb W N E S score\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003Ewhere\u003C\u002Fp\u003E\\n\u003Cul\u003E\\n\u003Cli\u003E\u003Ccode\u003EW\u003C\u002Fcode\u003E(est) \u003Ccode\u003EN\u003C\u002Fcode\u003E(orth) \u003Ccode\u003EE\u003C\u002Fcode\u003E(ast) \u003Ccode\u003ES\u003C\u002Fcode\u003E(outh) are decimal degrees\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003Escore\u003C\u002Fcode\u003E is the same as for option \u003Ccode\u003E-l\u003C\u002Fcode\u003E.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003Cp\u003EYou can grab the coordinates of a bounding box for a particular area using this online \u003Ca href=\\\"http:\u002F\u002Fboundingbox.klokantech.com\\\"\u003EBoundingBox\u003C\u002Fa\u003E tool. For example, a bounding box for Canada is \u003Ccode\u003E[W:-141.002701, N:83.110619, E:-52.620201, S:41.681019]\u003C\u002Fcode\u003E (see Figure 5)\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;geoparser_figure03.png&quot; caption=&quot;Figure 5: Bounding box for Canada drawn on \u003Ca href=\\\"http:\u002F\u002Fboundingbox.klokantech.com\\\"\u003EBoundingBox\u003C\u002Fa\u003E.&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003ETo specify this bounding box using the previous example, go back to the scripts directory and run the following command:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Ecat ..\u002Fin\u002F172172.txt | .\u002Frun -t plain -g geonames -lb -141.002701 83.110619 -52.620201 41.681019 2 -o ..\u002Fout 172172 \\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003EHere, the \u003Ccode\u003Escore\u003C\u002Fcode\u003E has been set to 2.  This gives a location within the bounding box twice as much weight as for example the population size of a location during geo-resolution.\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;geoparser_figure04.png&quot; caption=&quot;Figure 6: Display of file 172172.display.html after geo-parsing with a specified bounding box.&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003EIn this case, all place names (including Washington, Wimbledon, Germany and France) were resolved to locations within the bounding box (see Figure 6).  The locality option should therefore be used with care and should ideally only be applied to documents where you are relatively certain that all or most locations appear within the specified area.\u003C\u002Fp\u003E\\n\u003Ch3 id=\\\"specifying-a-document-date\\\"\u003ESpecifying a Document Date\u003C\u002Fh3\u003E\\n\u003Cp\u003EAs well as identifying locations and person names within text, the Geoparser also recognises temporal expressions (dates and times) in textual data and normalises them. Normalisation here means that the temporal expressions are enriched with additional information of when exactly they occurred. For example, it computes which the exact calendar date the expression &quot;last Friday&quot; refers to.\u003C\u002Fp\u003E\\n\u003Cp\u003EIn order to do this well, it is preferable to provide the Geoparser with the date of the document (if known). To try this out using the previous example, type the following command:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Ecat ..\u002Fin\u002F172172.txt | .\u002Frun -t plain -g geonames -d 2010-08-10 -o ..\u002Fout 172172 \\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cul\u003E\\n\u003Cli\u003E\u003Ccode\u003E-d\u003C\u002Fcode\u003E specifies the document date (\u003Ccode\u003EYEAR-MONTH-DATE\u003C\u002Fcode\u003E).  This option is optional.  It is used for normalisation (or grounding) of temporal expressions in the document, for example to compute which particular calendar date the string “Sunday” refers to.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003Cp\u003EThe document date specified on the command line is stored in the XML output and all relative temporal expression will be automatically interpreted with respect to it.  The document date (\u003Ccode\u003Edocdate\u003C\u002Fcode\u003E) is stored in the meta section at the top of the XML output file.  Use the \u003Ccode\u003Ehead\u003C\u002Fcode\u003E command to list the first 5 lines of the output file where you can see it:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Ehead -n 5 ..\u002Fout\u002F172172.out.xml\\n\\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\\n&lt;document version=&quot;3&quot;&gt;\\n&lt;meta&gt;\\n&lt;attr name=&quot;docdate&quot; id=&quot;docdate&quot; year=&quot;2010&quot; month=&quot;08&quot; date=&quot;10&quot; sdate=&quot;2010-08-10&quot; day-number=&quot;733993&quot; day=&quot;Tuesday&quot; wdaynum=&quot;2&quot;&gt;20100810&lt;\u002Fattr&gt;\\n&lt;attr name=&quot;tokeniser_version&quot; date=&quot;20151216&quot;\u002F&gt;&lt;\u002Fmeta&gt;\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003EUsing the example output file, the first recognised date string in the named  entity output is “Sunday” which appears in the sentence:\u003C\u002Fp\u003E\\n\u003Cblockquote\u003E\\n\u003Cp\u003E&quot;Rafael Nadal and Andy Murray are both through to the semifinals of the Rogers Cup in Toronto, where they will face each other for a place in Sunday&#39;s final.&quot;\u003C\u002Fp\u003E\\n\u003C\u002Fblockquote\u003E\\n\u003Cp\u003ESince the document date is Aug 8th 2010 which was a Tuesday, the Sunday referred to in this text is Aug 15th 2010.  The output of the correct temporal resolution for this example can be seen in the entity output in the standoff section of the \u003Ccode\u003E172172.out.xml\u003C\u002Fcode\u003E file:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003E&lt;ent date=&quot;15&quot; month=&quot;08&quot; year=&quot;2010&quot; sdate=&quot;2010-08-15&quot; day-number=&quot;733998&quot; id=&quot;rb7&quot; type=&quot;date&quot; day=&quot;Sunday&quot; wdaynum=&quot;7&quot;&gt;\\n   &lt;parts&gt;\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003E          \u003Cpart ew=\\\"w204\\\" sw=\\\"w204\\\"\u003ESunday\u003C\u002Fpart\u003E\\n       \u003C\u002Fparts\u003E\\n    \u003C\u002Fent\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003EBesides the obvious \u003Ccode\u003Edate\u003C\u002Fcode\u003E, \u003Ccode\u003Emonth\u003C\u002Fcode\u003E, \u003Ccode\u003Eyear\u003C\u002Fcode\u003E and \u003Ccode\u003Eday\u003C\u002Fcode\u003E attributes:\u003C\u002Fp\u003E\\n\u003Cul\u003E\\n\u003Cli\u003E\u003Ccode\u003Esdate\u003C\u002Fcode\u003E refers to the grounded date expressed as a string,\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003Eday-number\u003C\u002Fcode\u003E refers to a unique day number where 1 corresponds to the 1st of January 1 AD, and\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003Ewdaynum\u003C\u002Fcode\u003E refers to the week day number where 1 corresponds to Monday, 2 to Tuesday etc.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003Cp\u003EThis type of normalisation makes it possible to plot the events mentioned in a piece of text on a timeline.  A timeline view is automatically created at the end of each geoparser run. To view the one for our example \u003Ccode\u003E172172\u003C\u002Fcode\u003E, open the \u003Ccode\u003E172172.timeline.html\u003C\u002Fcode\u003E file in Firefox (this view is not configured for other browsers at the moment).\u003C\u002Fp\u003E\\n\u003Cp\u003EOn MacOSX:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Eopen -a Firefox .\u002Fout\u002F172172.timeline.html\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003EOn Linux:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Exdg-open .\u002Fout\u002F172172.timeline.html\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;geoparser_figure12.png&quot; caption=&quot;Figure 7: Timeline view for the example \u003Ccode\u003E172172\u003C\u002Fcode\u003E displayed in Firefox. You can see that the dates are normalised to the timeline at the bottom of the screen.&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003EFigure 7 is a screenshot of the timeline view in Firefox.  At the top of the screen you can see the text of the example with different entity types (person, location, organisation and temporal expression) marked up in different colours.  Underneath you can see the timeline view with normalised dates and their events pinned to the calendar.\u003C\u002Fp\u003E\\n\u003Cp\u003EIf the document date is not specified all temporal expressions will be interpreted relative to the date when the Geoparser is run.  While this setting does not affect the performance of the geo-resolution of place names in this release, one could imagine a possible extension where the document date affects the type of gazetteer used or the location name variants that should be considered as place names change over time.\u003C\u002Fp\u003E\\n\u003Ch3 id=\\\"geo-parsing-multiple-text-files\\\"\u003EGeo-parsing Multiple Text Files\u003C\u002Fh3\u003E\\n\u003Cp\u003ENow that you know how to geo-parse one file, you may want to do the same thing for a set of documents all at once. You can download a simple shell script which geo-parses multiple files \u003Ca href=\\\"http:\u002F\u002Fgroups.inf.ed.ac.uk\u002Fgeoparser\u002Fscripts\u002Frun-multiple-files.sh\\\"\u003Ehere\u003C\u002Fa\u003E. Please refer to the \u003Ca href=\\\"http:\u002F\u002Fhomepages.inf.ed.ac.uk\u002Fbalex\u002Fpublications\u002Fgeoparser-workshop.pdf\\\"\u003EGeoparser workshop\u003C\u002Fa\u003E slides for more information on how to make this script executable, run and it and adapt it to your needs.\u003C\u002Fp\u003E\\n\u003Ch3 id=\\\"extracting-geo-resolution-output-to-tsv\\\"\u003EExtracting Geo-Resolution Output to TSV\u003C\u002Fh3\u003E\\n\u003Cp\u003EThe output of the Geoparser is in XML format. This is useful as XML can store various types of information present in text along with it.  For example, it can store low-level information like the boundaries of words, their part-of-speech tags and lemmas.  It can also store more complex information like phrases and entities occurring in the text as well as links between them, for example the subject and object of a sentence or the location (e.g. birthplace) of a person.  The advantage is that all the computed structural and linguistic information computed for a piece of text is stored along with it and downstream natural language processing tools have all the information available.\u003C\u002Fp\u003E\\n\u003Cp\u003EWhile XML is easy to process by a machine it is difficult to read by human readers. You may also not be interested in all the information computed by the Geoparser and might only want to see which locations were identified along with their coordinates. So rather than dealing with an XML file, you might find it easier to work with the Geoparser output in a form such as tab-separated values (TSV) in order to inspect it in a spreadsheet or use it with an application such as QGIS or Google Maps\u002FGoogle Earth for which there are already useful Programming Historian lessons available (\u003Ca href=\\\"\u002Flessons\u002Fqgis-layers\\\"\u003EInstalling QGIS 2.0 and Adding Layers\u003C\u002Fa\u003E and \u003Ca href=\\\"\u002Flessons\u002Fgooglemaps-googleearth\\\"\u003EIntro to Google Maps and Google Earth\u003C\u002Fa\u003E).\u003C\u002Fp\u003E\\n\u003Cp\u003EThe Geoparser is distributed with a useful set of XML processing tools called \u003Ca href=\\\"https:\u002F\u002Fwww.ltg.ed.ac.uk\u002Fsoftware\u002Fltxml2\u002F\\\"\u003ELT-XML2\u003C\u002Fa\u003E, authored by Richard Tobin, which can be used to extract the location entities in a Geoparser XML output file and to present them in tab-separated value (TSV) format. The executables for these tools are located in the \u003Ccode\u003E.\u002Fgeoparser\u002Fbin\u003C\u002Fcode\u003E directory, inside:\u003C\u002Fp\u003E\\n\u003Cul\u003E\\n\u003Cli\u003E\u003Ccode\u003Esys-i386-64\u003C\u002Fcode\u003E: if you are using a 64 bit Linux machine or\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003Esys-i386-snow-leopard\u003C\u002Fcode\u003E: if you’re using MacOSX.  Don’t be confused by the name of this directory.  The executables should work for all MacOSX installations and not just on Snow Leopard.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003Cp\u003EAll the executables starting with \u003Cem\u003Elx\u003C\u002Fem\u003E are LT-XML tools which work in combination with Xpath expressions to process or manipulate XML.  Going in detail over Xpath is beyond the scope of this lesson, so I will give clear examples to show how things work.  If you are interested in XML data manipulation you will find further detail in \u003Ca href=\\\"\u002Flessons\u002Ftransforming-xml-with-xsl\\\"\u003ETransforming Data for Reuse and Re-publication\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\\n\u003Cp\u003EThe best tool for printing XML content in a different format is \u003Ccode\u003Elxprintf\u003C\u002Fcode\u003E. Depending on your operating system, go to the \u003Ccode\u003Egeoparser\u003C\u002Fcode\u003E directory and run \u003Ccode\u003Elxprintf\u003C\u002Fcode\u003E as follows:\u003C\u002Fp\u003E\\n\u003Cp\u003EOn Linux use:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003E.\u002Fbin\u002Fsys-i386-64\u002Flxprintf -e &quot;ent[@type=&#39;location&#39;]&quot; &quot;%s\\\\t%s\\\\t%s\\\\t%s\\\\t%s\\\\n&quot; &quot;normalize-space(parts\u002Fpart)&quot; &quot;@gazref&quot; &quot;@in-country&quot; &quot;@lat&quot; &quot;@long&quot; &lt; .\u002Fout\u002F172172.out.xml&gt; .\u002Fout\u002F172172.out.tsv\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003Eand on MacOSX type:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003E.\u002Fbin\u002Fsys-i386-snow-leopard\u002Flxprintf -e &quot;ent[@type=&#39;location&#39;]&quot; &quot;%s\\\\t%s\\\\t%s\\\\t%s\\\\t%s\\\\n&quot; &quot;normalize-space(parts\u002Fpart)&quot; &quot;@gazref&quot; &quot;@in-country&quot; &quot;@lat&quot; &quot;@long&quot; &lt; .\u002Fout\u002F172172.out.xml&gt; .\u002Fout\u002F172172.out.tsv\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003EThe previous \u003Ccode\u003Elxprintf\u003C\u002Fcode\u003E command reads through a geo-parsed XML output file, extracts all location entities identified by the Geoparser and presents them in TSV format. In the example above, the XML input file (containing the location entities) is \u003Ccode\u003E.\u002Fout\u002F172172.out.xml\u003C\u002Fcode\u003E, and the TSV file is \u003Ccode\u003E.\u002Fout\u002F172172.out.tsv\u003C\u002Fcode\u003E. The \u003Ccode\u003E&lt;\u003C\u002Fcode\u003E symbol signifies &quot;standard in&quot; (or stdin) which tells the script to read in the file that follows it and the \u003Ccode\u003E&gt;\u003C\u002Fcode\u003E symbol signifies standard out (or stdout) which specifies sending the output to the file that follows it.\u003C\u002Fp\u003E\\n\u003Cp\u003EThe way this command works is that lxprintf looks for XML entities specified after the option \u003Ccode\u003E-e\u003C\u002Fcode\u003E.  In this case, entities of type location are to be extracted (\u003Ccode\u003E&quot;ent[@type=&#39;location’]”\u003C\u002Fcode\u003E).  Here is an example of an entity of type location in the XML:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003E&lt;ent id=&quot;rb6&quot; type=&quot;location&quot; lat=&quot;43.70011&quot; long=&quot;-79.4163&quot; gazref=&quot;geonames:6167865&quot; in-country=&quot;CA&quot; feat-type=&quot;ppla&quot; pop-size=&quot;4612191&quot;&gt;\\n  &lt;parts&gt;\\n    &lt;part ew=&quot;w148&quot; sw=&quot;w148&quot;&gt;Toronto&lt;\u002Fpart&gt;\\n  &lt;\u002Fparts&gt;\\n&lt;\u002Fent&gt;\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003EThe next part of the command (\u003Ccode\u003E“%s\\\\t%s\\\\t%s\\\\t%s\\\\t%s\\\\n”\u003C\u002Fcode\u003E) specifies how the output should be printed.  In this case, each specified string (\u003Ccode\u003E%s\u003C\u002Fcode\u003E) is delimited by a tab (\u003Ccode\u003E\\\\t\u003C\u002Fcode\u003E) character and the last string is followed by a new line.  In this case, the following 5 strings for each location entity are specified:\u003C\u002Fp\u003E\\n\u003Cul\u003E\\n\u003Cli\u003E\u003Ccode\u003E&quot;normalize-space(parts)&quot;\u003C\u002Fcode\u003E refers to the location mention recognised in the text. normalize() removes any unnecessary whitespace.\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003E&quot;@gazref”\u003C\u002Fcode\u003E refers to the ID reference of the location in the gazetteer, if resolved.\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003E&quot;@in-country”\u003C\u002Fcode\u003E refers to the country the location appears in, if this information was identified.\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003E&quot;@lat”\u003C\u002Fcode\u003E refers to the latitude of the location, if this information was identified.\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ccode\u003E&quot;@long”\u003C\u002Fcode\u003E refers to the longitude of the location, if this information was identified.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003Cp\u003EWhen printed to screen, the content of the TSV output file is therefore the following:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Ecat .\u002Fout\u002F172172.out.tsv\\n\\nToronto geonames:6167865        CA      43.70011        -79.4163\\nGermany geonames:2921044        DE      51.5    10.5\\nWashington      geonames:4140963        US      38.89511        -77.03637\\nMontreal        geonames:6077243        CA      45.50884        -73.58781\\nWimbledon       geonames:4668339        US      35.71814        -83.97907\\nFrance  geonames:3017382        FR      46      2\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003EIf you open \u003Ccode\u003E.\u002Fout\u002F172172.out.tsv\u003C\u002Fcode\u003E in Excel, for example, you can see that the information is now presented in column format, in this case listing the place name, the GeoNames ID, the country code, the latitude and the longitude (see Figure 8).\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;geoparser_figure10.png&quot; caption=&quot;Figure 8: Geo-parsed location information from the example \u003Ccode\u003E172172\u003C\u002Fcode\u003E displayed in Excel.&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003EOnce you have extracted the geo-location information from the \u003Ccode\u003E*out.xml\u003C\u002Fcode\u003E file(s) you can use it as input into your favourite mapping tool though you will have to adjust the format depending on your needs.\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Ca name=\\\"patch_fix\\\"\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"patch-fix\\\"\u003EPatch Fix\u003C\u002Fh2\u003E\\n\u003Cp\u003EIf your machine is running maxOS Sierra (Darwin 16.7.0) or later versions you will get an error message similar to the following when running the Geoparser version 1.1:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003Eunrecognised platform Darwin 16.7.0 x86_64\\nedit scripts\u002Fsetup, or set LXPATH to appropriate path\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003EYou need to apply the following patch fix to get it to work properly. Open the \u003Ccode\u003Esetup\u003C\u002Fcode\u003E file in the \u003Ccode\u003Escripts\u003C\u002Fcode\u003E directory with your favourite editor and replace the following line:\u003C\u002Fp\u003E\\n\u003Cp\u003E  \u003Ccode\u003EDarwin?1[012345]*)\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003Ewith\u003C\u002Fp\u003E\\n\u003Cp\u003E  \u003Ccode\u003EDarwin?1[0-9]*)\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003EWe will release a new version shortly which will fix is this error.\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"credits-and-citation\\\"\u003ECredits and Citation\u003C\u002Fh2\u003E\\n\u003Cp\u003EThe Geoparser and its demo were developed over a number of years in a team effort by members of the \u003Ca href=\\\"https:\u002F\u002Fwww.ltg.ed.ac.uk\u002F\\\"\u003EEdinburgh Language Technology Group\u003C\u002Fa\u003E, including Claire Grover, Richard Tobin, Kate Byrne and myself (Beatrice Alex).\u003C\u002Fp\u003E\\n\u003Cp\u003EIf you found this lesson useful for your work, please cite it as:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003EBeatrice Alex. 2017. Geoparsing Text with the Edinburgh Geoparser, The Programming Historian lesson, \u002Flessons\u002Fgeoparsing-text-with-edinburgh, 2017.\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003Eor cite one of the publications listed \u003Ca href=\\\"https:\u002F\u002Fwww.ltg.ed.ac.uk\u002Fsoftware\u002Fgeoparser\u002F\\\"\u003Ehere\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\\n\u003Cp\u003EThe lesson is also available in workshop form.  If you&#39;re interested in running a workshop on how to use the Edinburgh Geoparser, do get in touch.\u003C\u002Fp\u003E\\n\u003Cp\u003EThe Geoparser team also welcomes suggestions for future collaboration to tailor the Geoparser to different needs.  Please get in touch if you have ideas about how it could be applied.\u003C\u002Fp\u003E\\n\u003Cp\u003EIn the past the Geoparser was used to identify place names for different purposes and in different types of data (e.g. Grover et al., 2010 and Alex et al., 2015).  For example, it was adapted to perform fine-grained geo-parsing for literature set in Edinburgh (\u003Ca href=\\\"http:\u002F\u002Fpalimpsest.blogs.edina.ac.uk\u002F\\\"\u003EPalimpsest\u003C\u002Fa\u003E) presented in the \u003Ca href=\\\"http:\u002F\u002Flitlong.org\u002F\\\"\u003ELitLong\u003C\u002Fa\u003E interface.  It was used to geo-parse\u003C\u002Fp\u003E\\n\u003Cul\u003E\\n\u003Cli\u003Evolumes of the Survey of English Place Names (\u003Ca href=\\\"http:\u002F\u002Fweb.archive.org\u002Fweb\u002F20170722115758\u002Fhttp:\u002F\u002Fenglishplacenames.cerch.kcl.ac.uk\u002F\\\"\u003EDEEP\u003C\u002Fa\u003E, see Grover and Tobin, 2014),\u003C\u002Fli\u003E\\n\u003Cli\u003Elarge historical collections related to commodity trading in the 19th century British Empire (\u003Ca href=\\\"http:\u002F\u002Ftradingconsequences.blogs.edina.ac.uk\u002F\\\"\u003ETrading Consequences\u003C\u002Fa\u003E) and\u003C\u002Fli\u003E\\n\u003Cli\u003E19th century British newspapers by \u003Ca href=\\\"http:\u002F\u002Fwww.lancaster.ac.uk\u002Fstaff\u002Fgregoryi\u002F\\\"\u003EProf. Ian Gregory\u003C\u002Fa\u003E’s group at Lancaster University.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003Cp\u003EThe Geoparser was also adapted to the ancient world for the \u003Ca href=\\\"https:\u002F\u002Fgoogleancientplaces.wordpress.com\u002F\\\"\u003EGoogle Ancient Places\u003C\u002Fa\u003E project (e.g. see Isaksen et al., 2011), with its \u003Ca href=\\\"http:\u002F\u002Fnrabinowitz.github.io\u002Fgapvis\u002F\\\"\u003EGapVis\u003C\u002Fa\u003E  interface. More recently, the Geoparser was used to geo-parse Twitter user profile locations (Alex et al, 2016).\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"references\\\"\u003EReferences\u003C\u002Fh2\u003E\\n\u003Cp\u003EBeatrice Alex, Clare Llewellyn, Claire Grover, Jon Oberlander and Richard Tobin (2016). Homing in on Twitter users: Evaluating an Enhanced Geoparser for User Profile Locations. 2016. In the Proceedings of the 10th Language Resources and Evaluation Conference (LREC), 23-28 May 2016. [\u003Ca href=\\\"http:\u002F\u002Fwww.lrec-conf.org\u002Fproceedings\u002Flrec2016\u002Fpdf\u002F129_Paper.pdf\\\"\u003Epdf\u003C\u002Fa\u003E]\u003C\u002Fp\u003E\\n\u003Cp\u003EBeatrice Alex, Kate Byrne, Claire Grover and Richard Tobin (2015). Adapting the Edinburgh Geoparser for Historical Georeferencing. International Journal for Humanities and Arts Computing, 9(1), pp. 15-35, March 2015.[\u003Ca href=\\\"http:\u002F\u002Fwww.euppublishing.com\u002Fdoi\u002Fpdfplus\u002F10.3366\u002Fijhac.2015.0136\\\"\u003Epdf\u003C\u002Fa\u003E]\u003C\u002Fp\u003E\\n\u003Cp\u003EClaire Grover and Richard Tobin (2014). A Gazetteer and Georeferencing for Historical English Documents. In Proceedings of LaTeCH 2014 at EACL 2014. Gothenburg, Sweden. \u003Ca href=\\\"http:\u002F\u002Fwww.aclweb.org\u002Fanthology\u002FW14-0617\\\"\u003E[pdf]\u003C\u002Fa\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003EClaire Grover, Richard Tobin, Kate Byrne, Matthew Woollard, James Reid, Stuart Dunn, and Julian Ball (2010). Use of the Edinburgh Geoparser for georeferencing digitised historical collections. Philosophical Transactions of the Royal Society A. [\u003Ca href=\\\"http:\u002F\u002Fhomepages.inf.ed.ac.uk\u002Fgrover\u002Fpapers\u002FPTRS-A-2010-Grover-3875-89.pdf\\\"\u003Epdf\u003C\u002Fa\u003E]\u003C\u002Fp\u003E\\n\u003Cp\u003ELeif Isaksen, Elton Barker, Eric C. Kansa, Kate Byrne (2012). GAP: A NeoGeo Approach to Classical Resources. Leonardo 45 (1): 82–83. [\u003Ca href=\\\"https:\u002F\u002Fdirect.mit.edu\u002Fleon\u002Farticle\u002F45\u002F1\u002F82\u002F46956\u002FGAP-A-NeoGeo-Approach-to-Classical-Resources#.U48IuXWx15Q\\\"\u003Epdf\u003C\u002Fa\u003E]\u003C\u002Fp\u003E\\n\"}"}</script></div>
	</body>
</html>
