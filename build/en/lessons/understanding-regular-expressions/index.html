<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="description" content="" />
		<link rel="icon" href="/favicon.png" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		

		

		<link rel="stylesheet" href="/_app/assets/start-61d1577b.css">
		<link rel="modulepreload" href="/_app/start-c09d08cd.js">
		<link rel="modulepreload" href="/_app/chunks/vendor-9b9d6288.js">
		<link rel="modulepreload" href="/_app/pages/__layout.svelte-de46afb2.js">
		<link rel="modulepreload" href="/_app/pages/_lang_/__layout.svelte-e75718c6.js">
		<link rel="modulepreload" href="/_app/chunks/stores-191d1505.js">
		<link rel="modulepreload" href="/_app/pages/_lang_/_lessons_/_slug_/index.svelte-efe77d76.js">

		<script type="module">
			import { start } from "/_app/start-c09d08cd.js";
			start({
				target: document.querySelector("#svelte"),
				paths: {"base":"","assets":""},
				session: {},
				route: true,
				spa: false,
				trailing_slash: "never",
				hydrate: {
					status: 200,
					error: null,
					nodes: [
						import("/_app/pages/__layout.svelte-de46afb2.js"),
						import("/_app/pages/_lang_/__layout.svelte-e75718c6.js"),
						import("/_app/pages/_lang_/_lessons_/_slug_/index.svelte-efe77d76.js")
					],
					url: new URL("sveltekit://prerender/en/lessons/understanding-regular-expressions"),
					params: {lang:"en",lessons:"lessons",slug:"understanding-regular-expressions"}
				}
			});
		</script><script>
			if ('serviceWorker' in navigator) {
				navigator.serviceWorker.register('/service-worker.js');
			}
		</script>
	</head>
	<body>
		<div id="svelte">


The Programming Historian <a href="/en">English</a> <a href="/es">Spanish</a>
<br>
This is the en edition.

<h1>Understanding Regular Expressions</h1>

<!-- HTML_TAG_START --><p>{% include toc.html %}</p>
<h2 id="lesson-goals">Lesson Goals</h2>
<p>In this exercise we will use advanced find-and-replace capabilities in a
word processing application in order to make use of structure in a brief
historical document that is essentially a table in the form of prose.
Without using a general programming language, we will gain exposure to
some aspects of computational thinking, especially pattern matching,
that can be immediately helpful to working historians (and others) using
word processors, and can form the basis for subsequent learning with
more general programming environments.</p>
<p>We will start with something like this:</p>
<pre><code>Arizona. — Quarter ended June 30, 1907. Estimated population,
 122,931. Total number of deaths 292, including diphtheria 1, enteric
 fever 4, scarlet fever 11, smallpox 2, and 49 from tuberculosis.
</code></pre>
<p>And use pattern matching to transform it to something like this:</p>
<table>
<thead>
<tr>
<th align="left"></th>
<th align="left"></th>
<th align="left"></th>
<th align="left"></th>
<th align="left"></th>
</tr>
</thead>
<tbody><tr>
<td align="left">Arizona.</td>
<td align="left">Quarter ended June 30, 1907.</td>
<td align="left">Deaths</td>
<td align="left">diphtheria</td>
<td align="left">1</td>
</tr>
<tr>
<td align="left">Arizona.</td>
<td align="left">Quarter ended June 30, 1907.</td>
<td align="left">Deaths</td>
<td align="left">enteric fever</td>
<td align="left">4</td>
</tr>
<tr>
<td align="left">Arizona.</td>
<td align="left">Quarter ended June 30, 1907.</td>
<td align="left">Deaths</td>
<td align="left">scarlet fever</td>
<td align="left">11</td>
</tr>
<tr>
<td align="left">Arizona.</td>
<td align="left">Quarter ended June 30, 1907.</td>
<td align="left">Deaths</td>
<td align="left">smallpox</td>
<td align="left">2</td>
</tr>
<tr>
<td align="left">Arizona.</td>
<td align="left">Quarter ended June 30, 1907.</td>
<td align="left">Deaths</td>
<td align="left">tuberculosis</td>
<td align="left">49</td>
</tr>
</tbody></table>
<h2 id="what-are-regular-expressions-and-for-whom-is-this-useful">What Are Regular Expressions and for Whom Is this Useful?</h2>
<p>Perhaps you are not sure yet you want to be a <em>programming</em> historian,
you just want to work more effectively with your sources. Historians,
librarians, and others in the humanities and social sciences often work
with textual sources that have implicit structure. It is also not
unheard of in the humanities to have to do tedious textual work with
semi-structured notes and bibliographic references, where it can help to
have some knowledge of pattern-matching options.</p>
<p>As a simple example, if we want to find a reference to a particular
year, say 1877, in a document, it&#39;s easy enough to search for that
single date. But if we want to find any references to years in latter
half of the 19th century, it is impractical to search several dozen
times for 1850, 1851, 1852, etc., in turn. By using regular expressions
we can use a concise pattern like &quot;18[5-9][0-9]&quot; to effectively match
any year from 1850 to 1899.</p>
<p>In this exercise we will use LibreOffice Writer and LibreOffice Calc,
which are free software desktop applications for word processing and
spreadsheets, respectively. Installation packages for Linux, Mac, or
Windows can be downloaded from <a href="http://www.libreoffice.org/download">http://www.libreoffice.org/download</a>.
Other word processing software and programming languages have similar
pattern-matching capabilities. This exercise uses LibreOffice because it
is freely available, and its regular expression syntax is closer to what
you will find in programming environments than Microsoft Office&#39;s
syntax. If you complete this exercise and find regular expressions
useful, however, it should be relatively easy to adapt what you learn
and apply it in other contexts.</p>
<p>While we will start with simple patterns, we will get to more
complicated or intimidating-looking ones fairly quickly. The aim here is
to share what is involved in doing useful work with a plausible example,
and not to linger too long on first principles with simplified toy
examples. If you are impatient, it should be possible to go through the
examples fairly quickly by copying and pasting the patterns offered,
without necessarily following every detail, in order to get a general
sense of what is possible. If the result is promising, you could go
through a second time to decide what details could be useful to pick up
for your own work. But typing everything yourself is the best way to
make it your own.</p>
<h2 id="getting-the-text">Getting the Text</h2>
<p>{% include figure.html filename=&quot;regex_ia_image.png&quot; caption=&quot;Figure 1: Screenshot of the unstructured text&quot; %}</p>
<p>The Internet Archive has copies of hundreds of early 20th-century public
domain U.S. public health reports digitized through JSTOR and organized
under the title &#39;Early Journal Content.&#39; These are of a convenient
length for an exercise and can plausibly represent broad classes of
textual resources that are useful in many kinds of historical research.
For our exercise, we will use a five-page report of monthly morbidity
and mortality statistics for states and cities in the United States,
published in February 1908, available at
<a href="http://archive.org/details/jstor-4560629/">http://archive.org/details/jstor-4560629/</a>.</p>
<p>Take a moment to scan the pages through the <a href="http://archive.org/stream/jstor-4560629/4560629#page/n0/mode/2up">Read Online</a> link to
become familiar with it. This document is organized as paragraphs rather
than tables, but there are clearly latent structures that can help us
tabulate this ourselves. Nearly every paragraph of the report starts
with geographic information, specifies a time span for the statistics,
optionally includes a population estimate, and then reports deaths and
nonlethal cases of illness.</p>
<p>The page-flipping interface shows us what the original document looked
like. But if we want to tabulate figures and enable ourselves to make
comparisons and calculations over geography, we will need to represent
the document as text and numbers, and not just images. In addition to
offering several image formats for download, the Internet Archive makes
available plain-text versions that have been created by means of Optical
Character Recognition (OCR) software. OCR of old texts is often
imperfect, but what it produces is useful in ways images can&#39;t be; it
can be searched, copied, and edited as text.</p>
<p>Switch to the <a href="http://archive.org/stream/jstor-4560629/4560629_djvu.txt">Full Text</a> view. We will start from this base, ignoring
the last part of the previous report. Copy the text from &quot;STATISTICAL
REPORTS…&quot; to the end into a new LibreOffice document. When working with
material you care about, be sure to save a copy somewhere separately
from your working copy, so that you can get back to your original if
something goes wrong.</p>
<h2 id="ordinary-search-and-replace">Ordinary search and replace</h2>
<p>We can see some Optical Character Recognition (OCR) errors, where the
Internet Archive&#39;s automated transcription software has made mistakes,
although for the most part this looks like a good transcription. There
are two places where the OCR has inserted double quotation marks into
this file mistakenly, in both cases by putting them between a comma
following a month and a four-digit year, as in</p>
<pre><code>December,&quot; 1907.
</code></pre>
<p>We can find these by doing a search (<code>Edit → Find</code> with shortcut Ctrl-F
or Cmd-F on a Mac) for double quotation marks, and confirm that these
are the only two instances of quotation marks in the file. In this case
we can simply delete them. Rather than do so by hand, just for practice
try using LibreOffice&#39;s find-and-replace function (<code>Ctrl-H</code> or
<code>Cmd-Alt-F</code> on Mac).</p>
<p><em>Replace</em> <code>&quot;</code> <em>with nothing.</em></p>
<p>{% include figure.html filename=&quot;regex_01_findquote.png&quot; caption=&quot;Figure 2: Screenshot of Find and Replace feature&quot; %}</p>
<h2 id="finding-structure-for-rows">Finding structure for rows</h2>
<p>We are just getting started, but to estimate how far we have to go,
select the full text from LibreOffice Writer (<code>Ctrl-A</code>) and paste it
into LibreOffice Calc (<code>File-&gt;New-&gt;Spreadsheet</code>). Each line of text
becomes a single-celled row of the spreadsheet. What we would like is
for each row of the spreadsheet to represent one kind of record in a
consistent form. It would take a lot of tedious work to tabulate this by
hand with this as our starting point. In what follows we will be doing
all our work with regular expressions in Writer, but keep Calc open in
the background. We can return to it to paste future iterations and gauge
our progress.</p>
<p>Returning to Writer, we will want to get rid of the line breaks that
we don&#39;t need — but there are some end-of-line hyphenations we should
clean up first. This time we will start using regular expressions, but with a disclaimer that regular expression implementations differ in their handling of line breaks more than in their features for matching patterns within lines.</p>
<p>Regular expressions in LibreOffice do not readily match patterns of
text that extend across line breaks, so we will adopt an indirect
strategy . We will first replace line breaks with a placeholder
character — let&#39;s use <code>#</code>  — that does not otherwise appear in our
text.</p>
<p>In the Find &amp; Replace box show <code>More Options</code> (Other Options on Mac)
and make sure the <code>Regular expressions</code> checkbox is selected. This
will enable us to use special symbols to define general patterns to
match.</p>
<p>Using find-and-replace,</p>
<p><em>replace</em> <code>$</code> <em>with <code>#</code>.</em></p>
<p>{% include figure.html filename=&quot;regex_02_moreoptions.png&quot; caption=&quot;Figure 3: The &#39;More Options&#39; tab in Open Office Find &amp; Replace&quot; %}</p>
<p>The dollar sign symbol
is a special symbol that traditionally matches the end of each line in
order to anchor a larger pattern. However, while it can have this
function in LibreOffice in larger patterns, LibreOffice will not let
us let us match text across line breaks. But LibreOffice will let us
use the <code>$</code> character on its own, without other patterns, to match and
replace line breaks independent of other characters.</p>
<p>To carry out a search and replace operation, you might start by
clicking <code>Find</code> and then <code>Replace</code> when you see that the highlighted
selection matches your expectations. After repeating this a few times
you can click <code>Replace All</code> to replace all the rest at once. If you
make a mistake or are uncertain, you can undo recent steps with <code>Edit → Undo</code> from the menu bar, or keyboard shortcut <code>Ctrl+Z</code> (Cmd+Z on
Mac).</p>
<p>In this document replacing line ends results in 291
replacements. (Your number may differ slightly depending on the number
of lines you copied.)  This sequence of replacements will make the
text less readable, temporarily, but it&#39;s necessary because we cannot
match patterns across line breaks, but we can match across a <code>#</code>
character.</p>
<p>Next let&#39;s close up our hyphenated words. This in fact can now be
accomplished by literal replacement without relying on generalized
pattern matching.</p>
<p>Again using find-and-replace,</p>
<p><em>replace all</em> <code>- #</code> <em>(hyphen-space-hash) with nothing.</em></p>
<p>This will close up patterns like &quot;tuber- #culosis&quot; to &quot;tuberculosis&quot; on one line, and will make a total of 27 replacements in this case.</p>
<p>Next:</p>
<p><em>replace all</em> <code>##</code> with <code>\n</code>.</p>
<p>This results in 71 replacements. In this step we take what were originally paragraph breaks, which appeared as double line breaks, and then were represented as doubled <code>#</code> characters, and we turn them back again into actual single line breaks. These will function in a spreadsheet context to mark new rows.</p>
<p>To conclude our line break work:</p>
<p><em>replace all</em> <code>#</code> <em>with</em> <code> </code> *(a single space). This will get rid of 122 line breaks that were not paragraph breaks in the original text.</p>
<p>At first it may not be clear what happened here, but this has in fact
made each paragraph a single paragraph or logical line. In LibreOffice
(and similar word processing programs) you can turn on nonprinting
characters (View→Nonprinting Characters with shortcut <code>Ctrl-F10 on Windows or Linux</code>) to see line and paragraph breaks.</p>
<p>{% include figure.html filename=&quot;regex_03_lines.png&quot; caption=&quot;Figure 4: Non-Printing Characters in LibreOffice&quot; %}</p>
<p>As a last way of confirming that we are starting to get a more useful
structure from this, let&#39;s copy the full text from Writer again and
paste it into a blank spreadsheet. This should confirm that each health
record is now a separate row in the spreadsheet (although we also have
page headings and footnotes mixed in — we will clean those up shortly).</p>
<p>{% include figure.html filename=&quot;regex_04_calclines.png&quot; caption=&quot;Figure 5: The improved structure, shown in LibreOffice Calc&quot; %}</p>
<h2 id="finding-structure-for-columns">Finding structure for columns</h2>
<p>Spreadsheets organize information in two dimensions, rows and columns.
We have seen that lines in Writer correspond to rows in Calc. How do we
make columns?</p>
<p>Spreadsheet software can read and write plain-text files using any of
several conventions for representing breaks between columns. One common
format uses commas to separate columns, and such files are often stored
with the extension &quot;.csv&quot; for &quot;comma-separated values.&quot; Another common
variant is to use a tab character, a special kind of space, to separate
columns. Because our text contains commas, to avoid confusion we will
use a tab character to separate columns. Though one could save a
intermediate plain-text file, in this exercise we will assume we are
copying and pasting directly from Writer to Calc.</p>
<p>Back in Writer, let&#39;s start making columns by splitting the
place-and-time information from the reported numbers. Almost all reports
include the words</p>
<p><code>Total number of deaths</code></p>
<p>Search for this and replace it with exactly the same phrase, but with
&quot;\t&quot; at the front of the string representing a tab character:</p>
<p><code>\tTotal number of deaths</code></p>
<p>After making this replacement (which makes 53 changes), select all the
text and copy and paste it into an empty spreadsheet again.</p>
<p>Does it look like nothing changed? LibreOffice Calc is putting the full
text of each paragraph in a single cell, tabs and all. We need to insist
on a plain-text interpretation to get Calc to ask us what to do with
tabs. Let&#39;s try again. You can empty the spreadsheet conveniently by
selecting all (<code>Ctrl-A</code>) and deleting the selection.</p>
<p>In an empty spreadsheet, select <code>Edit → Paste Special,</code> (or right-click
to reach the same) and then select &quot;unformatted text&quot; from the options
in the window appears. That should result in a popup &quot;Text Import&quot;
window. Make sure the Tab checkbox is selected under Separator options
and then click &quot;OK&quot;. (Before clicking OK you may want to try checking
and unchecking Comma and Space as separators to preview what they would
do here, but we do not want to treat them as separators in this
context.)</p>
<p>Now we see the promising start of a table structure, with geography and
time span still in column A, but with &quot;Total number of deaths&quot; and
subsequent text clearly aligned in a separate column.</p>
<p>{% include figure.html filename=&quot;regex_05_2col.png&quot; caption=&quot;Figure 6: The newly tab-delimited version of the data shown in LibreOffice Calc&quot; %}</p>
<p>Do you have any instances that moved over into a third column or beyond?
In that case you may inadvertently have put in too many tabs. In the
structure we have right now we don&#39;t expect to ever see two tab
characters in a row. Back in LibreOffice Writer we can check for this
and fix the problem by searching for</p>
<p><code>\t\t</code> and replacing with <code>\t</code></p>
<p><strong>repeating as needed</strong> until no more double-tabs are found.</p>
<p>Sometimes multiple applications of a replacement pattern introduce
additional changes after the first, which may or may not be what we
intend, and sometimes multiple applications will have no effect beyond
the first application. It is worth keeping this distinction in mind
while working with regular expressions.</p>
<h2 id="the-general-idea-of-regular-expressions">The general idea of regular expressions</h2>
<p>Before doing any more practical work with the file, this is a good time
for a brief introduction to regular expressions. Regular expressions (or
&quot;regexes&quot; for short) are a way of defining patterns that can apply to
sequences of things. They have the funny name that they do because of
their origins in computer science and formal language theory, and they
are incorporated into most general programming languages.</p>
<p>Regexes are also often available in some form in advanced word
processors, providing a more powerful means of find-and-replace than
matching exact sequences letter by letter. There are different syntaxes
and implementations of regular expressions, and what we have available
in word processing programs often isn&#39;t as extensive, robust, or in
conformance with wider practice as what one finds in programming
language contexts, but there are essential common principles.
LibreOffice for the most part follows notational conventions that you
will see in other contexts. If you use a proprietary word processor you
will likely find similar functionality even if the notation differs.</p>
<table>
<thead>
<tr>
<th align="left"></th>
<th align="left"></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>A b 1 </code></td>
<td align="left">literals — letters, digits, and spaces match themselves</td>
</tr>
<tr>
<td align="left"><code>[Ab1]</code></td>
<td align="left">a character class, matching one instance of any of <code>A</code>, <code>b</code>, or <code>1</code> in this case</td>
</tr>
<tr>
<td align="left"><code>[a-z]</code></td>
<td align="left">all lowercase letters within a range</td>
</tr>
<tr>
<td align="left"><code>[0-9]</code></td>
<td align="left">all digits</td>
</tr>
<tr>
<td align="left"><code>.</code></td>
<td align="left">any character</td>
</tr>
<tr>
<td align="left"><code>*</code></td>
<td align="left">zero or more</td>
</tr>
<tr>
<td align="left"><code>+</code></td>
<td align="left">one or more</td>
</tr>
<tr>
<td align="left"><code>( )</code></td>
<td align="left">if contents within parentheses match, define a group for future reference</td>
</tr>
<tr>
<td align="left"><code>$1</code></td>
<td align="left">refer to a matched group (this is the notation in LibreOffice; other notations such as \1 are sometimes used elsewhere)</td>
</tr>
<tr>
<td align="left"><code>\t</code></td>
<td align="left">tab</td>
</tr>
<tr>
<td align="left"><code>^</code></td>
<td align="left">beginning of line</td>
</tr>
<tr>
<td align="left"><code>$</code></td>
<td align="left">end of line</td>
</tr>
</tbody></table>
<p>For a more complete list of regular expressions in LibreOffice, see
their <a href="https://help.libreoffice.org/Common/List_of_Regular_Expressions">List of Regular Expressions</a>.</p>
<h2 id="applying-regular-expressions">Applying regular expressions</h2>
<p>Let&#39;s start to use some of these to remove the page headings with date
and page number. Switch back to your LibreOffice Writer window.</p>
<p><em>Replace:</em> <code>^.*February 21.*1908.*$</code> <em>with nothing</em> (4 matches).</p>
<p><em>Replace</em> <code>^.*Received out of regular order.*$</code> <em>with nothing</em> (2
matches).</p>
<p>Here <code>^</code> (caret) matches the beginning of the line, <code>.</code> (period) matches
any character, <code>.*</code> (period-asterisk) matches any sequence of zero or
more characters, and <code>$</code> (dollar-sign) matches the end of the line. By
spelling out the date, we will match only the lines where that sequence
appears, letter by letter, and by using <code>.*</code> at both ends we match all
lines with that sequence regardless of what else is before or after it
on the line. After making this replacement, we will be left with some
blank lines.</p>
<p>To remove the blank lines in LibreOffice,</p>
<p><em>Replace</em> <code>^$</code> <em>with nothing</em> (5 matches).</p>
<p>(In other regular expression environments, other techniques for working
with line endings will be necessary; some may be more convenient than
what LibreOffice offers, but this will work now for our purposes.)</p>
<p>Some records list a state, some a city with the state implicit, some a
state and city together. The text does not have enough structure to give
us a reliable way of distinguishing the California and Oakland records
so that we will be able automatically to put California in a state
column and Oakland in a city column. We will eventually need to do some
editing by hand, drawing on our own knowledge. But there is a lot of
consistency in the references to spans of time. We can use those
references to develop structures that will help keep similar segments
aligned across rows.</p>
<p>For convenience, let&#39;s put some markers in the text that won&#39;t be
confused with anything already present. We can easily distinguish these
markers from existing text, and easily remove them later when we don&#39;t
need them. Let&#39;s match time span references and put &quot;&lt;t&gt;&quot; at the
beginning of them and &quot;&lt;/t&gt;&quot; at the end, with the mnemonic &quot;t&quot; for
time. We could put a more verbose marker in, like &quot;&lt;time&gt;&quot; or a more
meaningless and untidy-looking one, like &quot;asdfJKL;&quot; as long as that
sequence wasn&#39;t for some reason already in our text. But in this
exercise we will use markers like &quot;&lt;t&gt;&quot; If you have seen HTML or XML,
these look a lot like the tags that mark elements. We are not creating
acceptable HTML or well-formed XML by doing this, and we will remove
these markers quickly, but there is a resemblance.</p>
<p><strong>Obligatory warning:</strong> Regular expressions are powerful, but they do
have their limits and (when used to modify material that someone cares
about) they can be dangerous, in that a mistake can inadvertently remove
or scramble a lot of information quickly. Also, as XML aficionados may
passionately tell you, regular expressions are not up to the job of
general-purpose parsing of XML. After one sees how useful regular
expressions are at dealing with certain kinds of patterns, there is a
temptation to think, whenever we see a pattern that a computer ought to
be able to help with, that regular expressions are all we need. In many
cases that will turn out not to be true. Regular expressions are not
adequate to deal with hierarchically nested patterns that XML is good at
describing.</p>
<p>But that&#39;s OK. In the context of this tutorial, we don&#39;t claim to know
anything in particular about XML, or to care about formal language
grammars. We just want to put some convenient markers into a text in
order to get some leverage in making a relatively simple implicit
structure a bit more explicit, and we will take those markers out before
we are done. There is a reason why such markers are useful. If you find
yourself intrigued by what can be done with patterns in this exercise,
you may want to learn more about HTML and XML, and learn what can be
done with appropriate methods that their more explicit structure makes
possible.</p>
<h2 id="defining-segments">Defining segments</h2>
<p>The next few patterns will rapidly get more complicated. If you slow
down to consult the reference to how the symbols define patterns,
however, the patterns should start to make sense.</p>
<p>Geographic references in our text are followed by emdashes (dashes that
are roughly the width of the letter &#39;m&#39;; wider than endashes.) We can
replace these with tab characters, which will effectively help us put
states and cities in separate columns of the spreadsheet.</p>
<p><em>Replace</em> <code>[ ]?—[ ]?</code></p>
<p><em>with</em> <code>\t</code></p>
<p>You should have 42 matches. (One easy way to get the emdash into your
pattern is to copy and paste from an existing emdash in the text itself.
The square brackets aren&#39;t entirely necessary here, but help make
visible the fact that we are matching a blank space — optionally
matching it, thanks to the question mark. That means our pattern will
accept an emdash with or without a space on either or both sides of it.)</p>
<p>Now we will look for explicit references to time and wrap them in
&quot;&lt;t&gt;&quot; and &quot;&lt;/t&gt;&quot; markers before and after. Once we have those
markers they will provide some scaffolding on which we can build further
patterns. Note that in the next pattern we want to be sure to apply the
replacement just once, otherwise some time references may be repeatedly
wrapped. It will be most efficient to use <code>Replace All</code> just once for
each wrapping pattern.</p>
<p><em>Replace</em> <code>(Month of [A-Z][a-z, 0-9]+ 19[0-9][0-9].)</code></p>
<p><em>with</em> <code>&lt;t&gt;$1&lt;/t&gt;</code></p>
<p>{% include figure.html filename=&quot;regex_06_timemarkup.png&quot; caption=&quot;Figure 7: Finding time using Regular Expressions&quot; %}</p>
<p>Here we are using parentheses to define everything that we match in the
search pattern as a single group, and in the replacement pattern we use
$1 to simply repeat that match, with a few additional characters before
and after it.</p>
<p>In addition to months, we need to match quarterly reports with a similar
approach:</p>
<p><em>Replace</em> <code>([-A-Za-z ]+ ended [A-Z][a-z, 0-9]+ 19[0-9][0-9].)</code></p>
<p><em>with</em> <code>&lt;t&gt;$1&lt;/t&gt;</code></p>
<p>You should have 7 more matches. It looks like we have references to time
accounted for. Extending this strategy to other kinds of information
here, let&#39;s use &quot;&lt;p&gt;&quot; for population estimates, &quot;&lt;N&gt;&quot; for total
number of deaths, and &quot;&lt;c&gt;&quot; for the word &quot;Cases,&quot; which separates
mortality from morbidity. (If you are familiar with HTML or XML, you may
recognize &quot;&lt;p&gt;&quot; as a paragraph marker. We&#39;re not using it in the same
way here.)</p>
<p>Here are some patterns to wrap each of those kinds of information, all
using the same strategy we just used:</p>
<p><em>Replace</em> <code>(Estimated population, [0-9,]+.)</code></p>
<p><em>with</em> <code>&lt;p&gt;$1&lt;/p&gt;</code> (34 matches).</p>
<p><em>Replace</em> <code>(Total number of deaths[A-Za-z ,]* [0-9,]+)</code></p>
<p><em>with</em> <code>&lt;N&gt;$1&lt;/N&gt;</code> (48 matches).</p>
<p><em>Replace</em> <code>(Cases ?:)</code></p>
<p><em>with</em> <code>&lt;c&gt;$1&lt;/c&gt;</code> (49 matches).</p>
<p>This next part is a little trickier. It would be great if we could get
hold of the disease (let&#39;s use &quot;&lt;d&gt;&quot;) and count (&quot;&lt;n&gt;&quot;) segments.
Because the prose in this document is so formulaic, especially following
the indication of total number of deaths, in this case we will be able
to get pretty far without having to match each disease name explicitly,
one by one. First match the disease-count pair after the word
&quot;including&quot;:</p>
<p><em>Replace</em> <code>&lt;/N&gt; including ([A-Za-z ]+) ([0-9]+),</code></p>
<p><em>with</em> <code>&lt;/N&gt; including &lt;d&gt;$1&lt;/d&gt; &lt;n&gt;$2&lt;/n&gt;</code> (29 matches).</p>
<p>And then iteratively match disease-count pairs that appear after
existing markers:</p>
<p><em>Replace</em> <code>&gt; ([A-Za-z ]+) ([0-9]+)([.,])</code></p>
<p><em>with</em> <code>&gt; &lt;d&gt;$1&lt;/d&gt; &lt;n&gt;$2&lt;/n&gt;</code></p>
<p>Note that we are getting rid of commas after the disease counts by
ignoring the third match in our replacement.</p>
<p><strong>Repeat</strong> this replacement as many times as necessary until there are
no further matches. It should take you seven iterations.</p>
<p>Our patterns have not done anything with phrases like &#39;and 3 from
tuberculosis.&#39; We can match those phrases and reverse the order so that
the disease name appears before the count:</p>
<p><em>Replace</em> <code>and ([0-9])+ from ([a-z ]+)</code></p>
<p><em>with</em> <code>&lt;d&gt;$2&lt;/d&gt; &lt;n&gt;$1&lt;/n&gt;</code> (32 matches).</p>
<p>It looks like our markers are now capturing a lot of the semantic
structure that we are interested in. Now let&#39;s copy and paste (&quot;paste
special … unformatted&quot;) into LibreOffice Calc to see how close we are to
getting a table. We are successfully separating location data into
cells, but the cells are not aligned vertically yet. We want to get all
of the time references into the third column.</p>
<p>{% include figure.html filename=&quot;regex_09_calc_3col.png&quot; caption=&quot;Figure 8: Measuring progress using LibreOffice Calc&quot; %}</p>
<p>The instances with two columns of location information should already be
OK. The rows with one location need an extra column. Most are cities, so
we will put the locations into the second column, and in a few instances
we will need to move state names back to the first column by hand. Go
back to your LibreOffice Writer window and:</p>
<p><em>Replace</em> <code>^([A-Za-z .]+\t&lt;t&gt;)</code></p>
<p><em>with</em> <code>\t$1</code> (30 matches).</p>
<p>Now fix the cases with no location information, where the location is
implicitly the same as the row above, and the time span is different.</p>
<p><em>Replace</em> <code>^&lt;t&gt;</code></p>
<p><em>with</em> <code>\t\t&lt;t&gt;</code> (19 matches)</p>
<p>{% include figure.html filename=&quot;regex_10_loc_columns.png&quot; caption=&quot;Figure 9: Further refining the results&quot; %}</p>
<p>The first few columns should look better after pasting this again into
Calc. The Writer text is still our working copy, so if you want to fix
up the state names, you could do so now in Writer by deleting the tab
character before a state name and introducing a new tab character after
it. Or you could wait until we are done with our work in Writer, and fix
them in Calc after we are ready for that to be our live working copy.
But we are not there yet.</p>
<p>We need to decide how to handle the lists of diseases. The rows have
different lists of varying lengths. While it would be easy enough now to
insert tab characters to put each disease and mortality or morbidity
count into a separate column, the columns would not be that helpful.
Diseases and tallies would not be vertically aligned. What we can do
instead is make a new row for each disease. The reports distinguish
between mortality counts and morbidity counts, which are already
conveniently separated by &quot;Cases:&quot;. (There is one case, Indiana, where
the text marks this section with the word &quot;Morbidity&quot;. Our searching
patterns missed this. You can fix the markup there by hand now, if you
like, or ignore it since this is an exercise. It&#39;s a good example of how
automated tools aren&#39;t a full substitute for editing or looking at your
sources, and it won&#39;t be the last such example.)</p>
<p>We can start by making a new row for &quot;cases&quot; lists, so that we can
handle them separately. Head back to LibreOffice Writer.</p>
<p>{% include figure.html filename=&quot;regex_11_writer_cases_together_hi.png&quot; caption=&quot;Figure 10: Making a new row for &#39;cases&#39;&quot; %}</p>
<p><em>Replace</em> <code>^(.*\t)(.*\t)(&lt;t&gt;.*&lt;/t&gt;)(.*)(&lt;c&gt;.*)</code></p>
<p><em>with</em> <code>$1$2$3$4\n$1$2$3\t$5</code> (47 matches).</p>
<p>One thing to notice here is that we are using some of the replacement
patterns twice. We are matching the three fields up to the time
reference, then matching everything before &quot;&lt;c&gt;&quot; in a fourth group,
and everything from &quot;&lt;c&gt;&quot; on in a fifth. In the replacement pattern,
we put groups 1-4 back in order, then introduce a newline and print
groups 1-3 again, followed by a tab and group 5. We&#39;ve effectively moved
the case listings to their own lines, and copied the place and time
fields verbatim.</p>
<p>Let&#39;s go further, and split all the case lists into separate rows:</p>
<p><em>Replace</em> <code>^(.*\t)(.*\t)(&lt;t&gt;.*&lt;/t&gt;)(.*&lt;c&gt;.*)(&lt;d&gt;.*&lt;/d&gt;) (&lt;n&gt;.*&lt;/n&gt;)</code></p>
<p><em>with</em> <code>$1$2$3$4\n$1$2$3\tCases\t$5$6</code></p>
<p>and <strong>repeat</strong> as many times as necessary until there are no more
replacements (seven iterations).</p>
<p>Now similarly split all the mortality lists into separate rows:</p>
<p><em>Replace</em> <code>^(.*\t)(.*\t)(&lt;t&gt;.*&lt;/t&gt;)(.*&lt;N&gt;.*)(&lt;d&gt;.*&lt;/d&gt;) (&lt;n&gt;.*&lt;/n&gt;)</code></p>
<p><em>with</em> <code>$1$2$3$4\n$1$2$3\tDeaths\t$5$6</code></p>
<p>and <strong>repeat</strong> as many times as necessary until there are no more
replacements (eight iterations).</p>
<p>This is getting very close now to a tabular structure, as you can see if
you paste again into Calc, though if you want to wait just a bit, some
cleanup work with short and simple patterns will get us most of the rest
of the way:</p>
<p><em>Replace</em> <code>.*&lt;/c&gt; $</code> <em>with nothing</em></p>
<p><em>Replace</em> <code>^$</code> <em>with nothing</em></p>
<p><em>Replace</em> <code>&lt;n&gt;</code></p>
<p><em>with</em> <code>\t</code></p>
<p><em>Replace</em> <code>&lt;/n&gt;</code> <em>with nothing</em></p>
<p><em>Replace</em> <code>&lt;d&gt;and</code></p>
<p><em>with</em> <code>&lt;d&gt;</code></p>
<p><em>Replace</em> <code>&lt;/?[tdp]&gt;</code> <em>with nothing</em></p>
<p>{% include figure.html filename=&quot;regex_17_writer_done.png&quot; caption=&quot;Figure 11: The final view in LibreOffice Writer&quot; %}</p>
<p>Now copy and paste this into Calc, and you should see a (mostly)
well-structured table.</p>
<p>{% include figure.html filename=&quot;regex_18_calc_done.png&quot; caption=&quot;Figure 12: The final view in LibreOffice Calc&quot; %}</p>
<p>If this were not an exercise but a source we were editing for research
or publication, there are still things that we would need to fix. We
didn&#39;t do anything with estimated population figures. Our
pattern-matching wasn&#39;t sophisticated enough to manage everything. In
lines that didn&#39;t have patterns like &quot;Total number of deaths 292,
including,&quot; we missed all subsequent patterns that assumed we had
already put in an &quot;&lt;/N&gt;&quot; marker.</p>
<h2 id="next-possibilities">Next possibilities</h2>
<p>Some of these problems could be fixed by additional pattern-matching
steps, some by hand-editing of the source document at particular points
along the way, and some by later editing of the data in spreadsheet or
similar tabular form.</p>
<p>We might want to consider other structures for the table, too — perhaps
mortality and morbidity would be more convenient to tally if they were
in different columns. Word processors are not the best tools for making
use of these kinds of structures. Spreadsheets, XML, and programmatic
tools for working with data are much more likely to be helpful. But word
processors do have advanced find-and-replace functions that are good to
get to know. Regular expressions and advanced pattern matching can be
helpful in editing, and can provide a bridge between sequences with
implicit structure and more explicit structures that we may want to
match or create.</p>
<p>There are more than 400 public health reports like this one available
from the Internet Archive. If we wanted to tabulate all of them,
LibreOffice would not be the best primary tool. It would be better to
learn a little Python, Ruby, or shell scripting. Programmer-oriented
plain text editors, including classic ones such as Emacs and Vi or Vim,
have great regular expression support as well as other features useful
for dealing with plain text in a programmatic way. If you are
comfortable opening up a Unix-like shell command line (in Mac or Linux,
or on Windows through a virtual machine or the Cygwin environment), you
can learn and use regular expressions very well with tools like &quot;grep&quot;
for searching and &quot;sed&quot; for line-oriented replacing.</p>
<p>Regular expressions can be immensely useful in dealing with patterns
across hundreds of files at once. The patterns we have used in this
example would need to be refined and extended to deal with assumptions
that are certain to be mistaken when applied to longer texts or larger
sets of texts, but with a programming language we could record what we
are doing in a short script, and refine and rerun it repeatedly to get
closer to what we want.</p>
<h2 id="to-learn-more">To learn more</h2>
<p>The Wikipedia page on <a href="http://en.wikipedia.org/wiki/Regular_expressions">regular expressions</a> is a useful place to find
a brief history of regular expressions and their relation to formal
language theory, as well as an overview of syntactic variants and formal
standardization efforts.</p>
<p>The documentation for whatever tools you use will be invaluable for
practical use, especially for work in word processing environments where
regular expression implementations may be especially idiosyncratic.
There are many resources available to learn how to use regular
expressions in programming contexts; which is best for you may depend on
what programming language is most familiar or convenient to start with.</p>
<p>There are a number of freely available web-based regular expression
editors. <a href="http://rubular.com/">Rubular</a>, built on the Ruby programming language, has a
helpful interface that lets you test regular expressions against a
sample text and dynamically shows matches and matched groups. David
Birnbaum, Chair of the Department of Slavic Languages and Literatures at
the University of Pittsburg, has some good materials on how to work with
<a href="http://dh.obdurodon.org/regex.html">regular expressions and XML tools</a> to help mark up plain-text files
in TEI XML.</p>
<!-- HTML_TAG_END -->

<script type="application/json" data-type="svelte-data" data-url="understanding-regular-expressions/raw.json">{"status":200,"statusText":"","headers":{"content-type":"application/json; charset=utf-8"},"body":"{\"metadata\":{\"title\":\"Understanding Regular Expressions\",\"layout\":\"lesson\",\"date\":\"2013-06-22T00:00:00.000Z\",\"authors\":[\"Doug Knox\"],\"reviewers\":[\"Dave Shepard\",\"Patrick Burns\"],\"editors\":[\"Adam Crymble\"],\"difficulty\":2,\"exclude_from_check\":[\"review-ticket\"],\"activity\":\"transforming\",\"topics\":[\"data-manipulation\"],\"abstract\":\"In this lesson, we will use advanced find-and-replace capabilities in a word processing application in order to make use of structure in a brief historical document that is essentially a table in the form of prose.\",\"redirect_from\":\"\u002Flessons\u002Funderstanding-regular-expressions\",\"avatar_alt\":\"Person studying a book at a desk\",\"doi\":\"10.46430\u002Fphen0033\"},\"html_body\":\"\u003Cp\u003E{% include toc.html %}\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"lesson-goals\\\"\u003ELesson Goals\u003C\u002Fh2\u003E\\n\u003Cp\u003EIn this exercise we will use advanced find-and-replace capabilities in a\\nword processing application in order to make use of structure in a brief\\nhistorical document that is essentially a table in the form of prose.\\nWithout using a general programming language, we will gain exposure to\\nsome aspects of computational thinking, especially pattern matching,\\nthat can be immediately helpful to working historians (and others) using\\nword processors, and can form the basis for subsequent learning with\\nmore general programming environments.\u003C\u002Fp\u003E\\n\u003Cp\u003EWe will start with something like this:\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003EArizona. — Quarter ended June 30, 1907. Estimated population,\\n 122,931. Total number of deaths 292, including diphtheria 1, enteric\\n fever 4, scarlet fever 11, smallpox 2, and 49 from tuberculosis.\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003EAnd use pattern matching to transform it to something like this:\u003C\u002Fp\u003E\\n\u003Ctable\u003E\\n\u003Cthead\u003E\\n\u003Ctr\u003E\\n\u003Cth align=\\\"left\\\"\u003E\u003C\u002Fth\u003E\\n\u003Cth align=\\\"left\\\"\u003E\u003C\u002Fth\u003E\\n\u003Cth align=\\\"left\\\"\u003E\u003C\u002Fth\u003E\\n\u003Cth align=\\\"left\\\"\u003E\u003C\u002Fth\u003E\\n\u003Cth align=\\\"left\\\"\u003E\u003C\u002Fth\u003E\\n\u003C\u002Ftr\u003E\\n\u003C\u002Fthead\u003E\\n\u003Ctbody\u003E\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003EArizona.\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003EQuarter ended June 30, 1907.\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003EDeaths\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Ediphtheria\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003E1\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003EArizona.\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003EQuarter ended June 30, 1907.\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003EDeaths\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Eenteric fever\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003E4\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003EArizona.\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003EQuarter ended June 30, 1907.\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003EDeaths\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Escarlet fever\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003E11\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003EArizona.\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003EQuarter ended June 30, 1907.\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003EDeaths\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Esmallpox\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003E2\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003EArizona.\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003EQuarter ended June 30, 1907.\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003EDeaths\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Etuberculosis\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003E49\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003C\u002Ftbody\u003E\u003C\u002Ftable\u003E\\n\u003Ch2 id=\\\"what-are-regular-expressions-and-for-whom-is-this-useful\\\"\u003EWhat Are Regular Expressions and for Whom Is this Useful?\u003C\u002Fh2\u003E\\n\u003Cp\u003EPerhaps you are not sure yet you want to be a \u003Cem\u003Eprogramming\u003C\u002Fem\u003E historian,\\nyou just want to work more effectively with your sources. Historians,\\nlibrarians, and others in the humanities and social sciences often work\\nwith textual sources that have implicit structure. It is also not\\nunheard of in the humanities to have to do tedious textual work with\\nsemi-structured notes and bibliographic references, where it can help to\\nhave some knowledge of pattern-matching options.\u003C\u002Fp\u003E\\n\u003Cp\u003EAs a simple example, if we want to find a reference to a particular\\nyear, say 1877, in a document, it&#39;s easy enough to search for that\\nsingle date. But if we want to find any references to years in latter\\nhalf of the 19th century, it is impractical to search several dozen\\ntimes for 1850, 1851, 1852, etc., in turn. By using regular expressions\\nwe can use a concise pattern like &quot;18[5-9][0-9]&quot; to effectively match\\nany year from 1850 to 1899.\u003C\u002Fp\u003E\\n\u003Cp\u003EIn this exercise we will use LibreOffice Writer and LibreOffice Calc,\\nwhich are free software desktop applications for word processing and\\nspreadsheets, respectively. Installation packages for Linux, Mac, or\\nWindows can be downloaded from \u003Ca href=\\\"http:\u002F\u002Fwww.libreoffice.org\u002Fdownload\\\"\u003Ehttp:\u002F\u002Fwww.libreoffice.org\u002Fdownload\u003C\u002Fa\u003E.\\nOther word processing software and programming languages have similar\\npattern-matching capabilities. This exercise uses LibreOffice because it\\nis freely available, and its regular expression syntax is closer to what\\nyou will find in programming environments than Microsoft Office&#39;s\\nsyntax. If you complete this exercise and find regular expressions\\nuseful, however, it should be relatively easy to adapt what you learn\\nand apply it in other contexts.\u003C\u002Fp\u003E\\n\u003Cp\u003EWhile we will start with simple patterns, we will get to more\\ncomplicated or intimidating-looking ones fairly quickly. The aim here is\\nto share what is involved in doing useful work with a plausible example,\\nand not to linger too long on first principles with simplified toy\\nexamples. If you are impatient, it should be possible to go through the\\nexamples fairly quickly by copying and pasting the patterns offered,\\nwithout necessarily following every detail, in order to get a general\\nsense of what is possible. If the result is promising, you could go\\nthrough a second time to decide what details could be useful to pick up\\nfor your own work. But typing everything yourself is the best way to\\nmake it your own.\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"getting-the-text\\\"\u003EGetting the Text\u003C\u002Fh2\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;regex_ia_image.png&quot; caption=&quot;Figure 1: Screenshot of the unstructured text&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003EThe Internet Archive has copies of hundreds of early 20th-century public\\ndomain U.S. public health reports digitized through JSTOR and organized\\nunder the title &#39;Early Journal Content.&#39; These are of a convenient\\nlength for an exercise and can plausibly represent broad classes of\\ntextual resources that are useful in many kinds of historical research.\\nFor our exercise, we will use a five-page report of monthly morbidity\\nand mortality statistics for states and cities in the United States,\\npublished in February 1908, available at\\n\u003Ca href=\\\"http:\u002F\u002Farchive.org\u002Fdetails\u002Fjstor-4560629\u002F\\\"\u003Ehttp:\u002F\u002Farchive.org\u002Fdetails\u002Fjstor-4560629\u002F\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\\n\u003Cp\u003ETake a moment to scan the pages through the \u003Ca href=\\\"http:\u002F\u002Farchive.org\u002Fstream\u002Fjstor-4560629\u002F4560629#page\u002Fn0\u002Fmode\u002F2up\\\"\u003ERead Online\u003C\u002Fa\u003E link to\\nbecome familiar with it. This document is organized as paragraphs rather\\nthan tables, but there are clearly latent structures that can help us\\ntabulate this ourselves. Nearly every paragraph of the report starts\\nwith geographic information, specifies a time span for the statistics,\\noptionally includes a population estimate, and then reports deaths and\\nnonlethal cases of illness.\u003C\u002Fp\u003E\\n\u003Cp\u003EThe page-flipping interface shows us what the original document looked\\nlike. But if we want to tabulate figures and enable ourselves to make\\ncomparisons and calculations over geography, we will need to represent\\nthe document as text and numbers, and not just images. In addition to\\noffering several image formats for download, the Internet Archive makes\\navailable plain-text versions that have been created by means of Optical\\nCharacter Recognition (OCR) software. OCR of old texts is often\\nimperfect, but what it produces is useful in ways images can&#39;t be; it\\ncan be searched, copied, and edited as text.\u003C\u002Fp\u003E\\n\u003Cp\u003ESwitch to the \u003Ca href=\\\"http:\u002F\u002Farchive.org\u002Fstream\u002Fjstor-4560629\u002F4560629_djvu.txt\\\"\u003EFull Text\u003C\u002Fa\u003E view. We will start from this base, ignoring\\nthe last part of the previous report. Copy the text from &quot;STATISTICAL\\nREPORTS…&quot; to the end into a new LibreOffice document. When working with\\nmaterial you care about, be sure to save a copy somewhere separately\\nfrom your working copy, so that you can get back to your original if\\nsomething goes wrong.\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"ordinary-search-and-replace\\\"\u003EOrdinary search and replace\u003C\u002Fh2\u003E\\n\u003Cp\u003EWe can see some Optical Character Recognition (OCR) errors, where the\\nInternet Archive&#39;s automated transcription software has made mistakes,\\nalthough for the most part this looks like a good transcription. There\\nare two places where the OCR has inserted double quotation marks into\\nthis file mistakenly, in both cases by putting them between a comma\\nfollowing a month and a four-digit year, as in\u003C\u002Fp\u003E\\n\u003Cpre\u003E\u003Ccode\u003EDecember,&quot; 1907.\\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\\n\u003Cp\u003EWe can find these by doing a search (\u003Ccode\u003EEdit → Find\u003C\u002Fcode\u003E with shortcut Ctrl-F\\nor Cmd-F on a Mac) for double quotation marks, and confirm that these\\nare the only two instances of quotation marks in the file. In this case\\nwe can simply delete them. Rather than do so by hand, just for practice\\ntry using LibreOffice&#39;s find-and-replace function (\u003Ccode\u003ECtrl-H\u003C\u002Fcode\u003E or\\n\u003Ccode\u003ECmd-Alt-F\u003C\u002Fcode\u003E on Mac).\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E&quot;\u003C\u002Fcode\u003E \u003Cem\u003Ewith nothing.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;regex_01_findquote.png&quot; caption=&quot;Figure 2: Screenshot of Find and Replace feature&quot; %}\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"finding-structure-for-rows\\\"\u003EFinding structure for rows\u003C\u002Fh2\u003E\\n\u003Cp\u003EWe are just getting started, but to estimate how far we have to go,\\nselect the full text from LibreOffice Writer (\u003Ccode\u003ECtrl-A\u003C\u002Fcode\u003E) and paste it\\ninto LibreOffice Calc (\u003Ccode\u003EFile-&gt;New-&gt;Spreadsheet\u003C\u002Fcode\u003E). Each line of text\\nbecomes a single-celled row of the spreadsheet. What we would like is\\nfor each row of the spreadsheet to represent one kind of record in a\\nconsistent form. It would take a lot of tedious work to tabulate this by\\nhand with this as our starting point. In what follows we will be doing\\nall our work with regular expressions in Writer, but keep Calc open in\\nthe background. We can return to it to paste future iterations and gauge\\nour progress.\u003C\u002Fp\u003E\\n\u003Cp\u003EReturning to Writer, we will want to get rid of the line breaks that\\nwe don&#39;t need — but there are some end-of-line hyphenations we should\\nclean up first. This time we will start using regular expressions, but with a disclaimer that regular expression implementations differ in their handling of line breaks more than in their features for matching patterns within lines.\u003C\u002Fp\u003E\\n\u003Cp\u003ERegular expressions in LibreOffice do not readily match patterns of\\ntext that extend across line breaks, so we will adopt an indirect\\nstrategy . We will first replace line breaks with a placeholder\\ncharacter — let&#39;s use \u003Ccode\u003E#\u003C\u002Fcode\u003E  — that does not otherwise appear in our\\ntext.\u003C\u002Fp\u003E\\n\u003Cp\u003EIn the Find &amp; Replace box show \u003Ccode\u003EMore Options\u003C\u002Fcode\u003E (Other Options on Mac)\\nand make sure the \u003Ccode\u003ERegular expressions\u003C\u002Fcode\u003E checkbox is selected. This\\nwill enable us to use special symbols to define general patterns to\\nmatch.\u003C\u002Fp\u003E\\n\u003Cp\u003EUsing find-and-replace,\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ereplace\u003C\u002Fem\u003E \u003Ccode\u003E$\u003C\u002Fcode\u003E \u003Cem\u003Ewith \u003Ccode\u003E#\u003C\u002Fcode\u003E.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;regex_02_moreoptions.png&quot; caption=&quot;Figure 3: The &#39;More Options&#39; tab in Open Office Find &amp; Replace&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003EThe dollar sign symbol\\nis a special symbol that traditionally matches the end of each line in\\norder to anchor a larger pattern. However, while it can have this\\nfunction in LibreOffice in larger patterns, LibreOffice will not let\\nus let us match text across line breaks. But LibreOffice will let us\\nuse the \u003Ccode\u003E$\u003C\u002Fcode\u003E character on its own, without other patterns, to match and\\nreplace line breaks independent of other characters.\u003C\u002Fp\u003E\\n\u003Cp\u003ETo carry out a search and replace operation, you might start by\\nclicking \u003Ccode\u003EFind\u003C\u002Fcode\u003E and then \u003Ccode\u003EReplace\u003C\u002Fcode\u003E when you see that the highlighted\\nselection matches your expectations. After repeating this a few times\\nyou can click \u003Ccode\u003EReplace All\u003C\u002Fcode\u003E to replace all the rest at once. If you\\nmake a mistake or are uncertain, you can undo recent steps with \u003Ccode\u003EEdit → Undo\u003C\u002Fcode\u003E from the menu bar, or keyboard shortcut \u003Ccode\u003ECtrl+Z\u003C\u002Fcode\u003E (Cmd+Z on\\nMac).\u003C\u002Fp\u003E\\n\u003Cp\u003EIn this document replacing line ends results in 291\\nreplacements. (Your number may differ slightly depending on the number\\nof lines you copied.)  This sequence of replacements will make the\\ntext less readable, temporarily, but it&#39;s necessary because we cannot\\nmatch patterns across line breaks, but we can match across a \u003Ccode\u003E#\u003C\u002Fcode\u003E\\ncharacter.\u003C\u002Fp\u003E\\n\u003Cp\u003ENext let&#39;s close up our hyphenated words. This in fact can now be\\naccomplished by literal replacement without relying on generalized\\npattern matching.\u003C\u002Fp\u003E\\n\u003Cp\u003EAgain using find-and-replace,\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ereplace all\u003C\u002Fem\u003E \u003Ccode\u003E- #\u003C\u002Fcode\u003E \u003Cem\u003E(hyphen-space-hash) with nothing.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003EThis will close up patterns like &quot;tuber- #culosis&quot; to &quot;tuberculosis&quot; on one line, and will make a total of 27 replacements in this case.\u003C\u002Fp\u003E\\n\u003Cp\u003ENext:\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ereplace all\u003C\u002Fem\u003E \u003Ccode\u003E##\u003C\u002Fcode\u003E with \u003Ccode\u003E\\\\n\u003C\u002Fcode\u003E.\u003C\u002Fp\u003E\\n\u003Cp\u003EThis results in 71 replacements. In this step we take what were originally paragraph breaks, which appeared as double line breaks, and then were represented as doubled \u003Ccode\u003E#\u003C\u002Fcode\u003E characters, and we turn them back again into actual single line breaks. These will function in a spreadsheet context to mark new rows.\u003C\u002Fp\u003E\\n\u003Cp\u003ETo conclude our line break work:\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ereplace all\u003C\u002Fem\u003E \u003Ccode\u003E#\u003C\u002Fcode\u003E \u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E \u003C\u002Fcode\u003E *(a single space). This will get rid of 122 line breaks that were not paragraph breaks in the original text.\u003C\u002Fp\u003E\\n\u003Cp\u003EAt first it may not be clear what happened here, but this has in fact\\nmade each paragraph a single paragraph or logical line. In LibreOffice\\n(and similar word processing programs) you can turn on nonprinting\\ncharacters (View→Nonprinting Characters with shortcut \u003Ccode\u003ECtrl-F10 on Windows or Linux\u003C\u002Fcode\u003E) to see line and paragraph breaks.\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;regex_03_lines.png&quot; caption=&quot;Figure 4: Non-Printing Characters in LibreOffice&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003EAs a last way of confirming that we are starting to get a more useful\\nstructure from this, let&#39;s copy the full text from Writer again and\\npaste it into a blank spreadsheet. This should confirm that each health\\nrecord is now a separate row in the spreadsheet (although we also have\\npage headings and footnotes mixed in — we will clean those up shortly).\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;regex_04_calclines.png&quot; caption=&quot;Figure 5: The improved structure, shown in LibreOffice Calc&quot; %}\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"finding-structure-for-columns\\\"\u003EFinding structure for columns\u003C\u002Fh2\u003E\\n\u003Cp\u003ESpreadsheets organize information in two dimensions, rows and columns.\\nWe have seen that lines in Writer correspond to rows in Calc. How do we\\nmake columns?\u003C\u002Fp\u003E\\n\u003Cp\u003ESpreadsheet software can read and write plain-text files using any of\\nseveral conventions for representing breaks between columns. One common\\nformat uses commas to separate columns, and such files are often stored\\nwith the extension &quot;.csv&quot; for &quot;comma-separated values.&quot; Another common\\nvariant is to use a tab character, a special kind of space, to separate\\ncolumns. Because our text contains commas, to avoid confusion we will\\nuse a tab character to separate columns. Though one could save a\\nintermediate plain-text file, in this exercise we will assume we are\\ncopying and pasting directly from Writer to Calc.\u003C\u002Fp\u003E\\n\u003Cp\u003EBack in Writer, let&#39;s start making columns by splitting the\\nplace-and-time information from the reported numbers. Almost all reports\\ninclude the words\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Ccode\u003ETotal number of deaths\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003ESearch for this and replace it with exactly the same phrase, but with\\n&quot;\\\\t&quot; at the front of the string representing a tab character:\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Ccode\u003E\\\\tTotal number of deaths\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003EAfter making this replacement (which makes 53 changes), select all the\\ntext and copy and paste it into an empty spreadsheet again.\u003C\u002Fp\u003E\\n\u003Cp\u003EDoes it look like nothing changed? LibreOffice Calc is putting the full\\ntext of each paragraph in a single cell, tabs and all. We need to insist\\non a plain-text interpretation to get Calc to ask us what to do with\\ntabs. Let&#39;s try again. You can empty the spreadsheet conveniently by\\nselecting all (\u003Ccode\u003ECtrl-A\u003C\u002Fcode\u003E) and deleting the selection.\u003C\u002Fp\u003E\\n\u003Cp\u003EIn an empty spreadsheet, select \u003Ccode\u003EEdit → Paste Special,\u003C\u002Fcode\u003E (or right-click\\nto reach the same) and then select &quot;unformatted text&quot; from the options\\nin the window appears. That should result in a popup &quot;Text Import&quot;\\nwindow. Make sure the Tab checkbox is selected under Separator options\\nand then click &quot;OK&quot;. (Before clicking OK you may want to try checking\\nand unchecking Comma and Space as separators to preview what they would\\ndo here, but we do not want to treat them as separators in this\\ncontext.)\u003C\u002Fp\u003E\\n\u003Cp\u003ENow we see the promising start of a table structure, with geography and\\ntime span still in column A, but with &quot;Total number of deaths&quot; and\\nsubsequent text clearly aligned in a separate column.\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;regex_05_2col.png&quot; caption=&quot;Figure 6: The newly tab-delimited version of the data shown in LibreOffice Calc&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003EDo you have any instances that moved over into a third column or beyond?\\nIn that case you may inadvertently have put in too many tabs. In the\\nstructure we have right now we don&#39;t expect to ever see two tab\\ncharacters in a row. Back in LibreOffice Writer we can check for this\\nand fix the problem by searching for\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Ccode\u003E\\\\t\\\\t\u003C\u002Fcode\u003E and replacing with \u003Ccode\u003E\\\\t\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cstrong\u003Erepeating as needed\u003C\u002Fstrong\u003E until no more double-tabs are found.\u003C\u002Fp\u003E\\n\u003Cp\u003ESometimes multiple applications of a replacement pattern introduce\\nadditional changes after the first, which may or may not be what we\\nintend, and sometimes multiple applications will have no effect beyond\\nthe first application. It is worth keeping this distinction in mind\\nwhile working with regular expressions.\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"the-general-idea-of-regular-expressions\\\"\u003EThe general idea of regular expressions\u003C\u002Fh2\u003E\\n\u003Cp\u003EBefore doing any more practical work with the file, this is a good time\\nfor a brief introduction to regular expressions. Regular expressions (or\\n&quot;regexes&quot; for short) are a way of defining patterns that can apply to\\nsequences of things. They have the funny name that they do because of\\ntheir origins in computer science and formal language theory, and they\\nare incorporated into most general programming languages.\u003C\u002Fp\u003E\\n\u003Cp\u003ERegexes are also often available in some form in advanced word\\nprocessors, providing a more powerful means of find-and-replace than\\nmatching exact sequences letter by letter. There are different syntaxes\\nand implementations of regular expressions, and what we have available\\nin word processing programs often isn&#39;t as extensive, robust, or in\\nconformance with wider practice as what one finds in programming\\nlanguage contexts, but there are essential common principles.\\nLibreOffice for the most part follows notational conventions that you\\nwill see in other contexts. If you use a proprietary word processor you\\nwill likely find similar functionality even if the notation differs.\u003C\u002Fp\u003E\\n\u003Ctable\u003E\\n\u003Cthead\u003E\\n\u003Ctr\u003E\\n\u003Cth align=\\\"left\\\"\u003E\u003C\u002Fth\u003E\\n\u003Cth align=\\\"left\\\"\u003E\u003C\u002Fth\u003E\\n\u003C\u002Ftr\u003E\\n\u003C\u002Fthead\u003E\\n\u003Ctbody\u003E\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003E\u003Ccode\u003EA b 1 \u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Eliterals — letters, digits, and spaces match themselves\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003E\u003Ccode\u003E[Ab1]\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Ea character class, matching one instance of any of \u003Ccode\u003EA\u003C\u002Fcode\u003E, \u003Ccode\u003Eb\u003C\u002Fcode\u003E, or \u003Ccode\u003E1\u003C\u002Fcode\u003E in this case\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003E\u003Ccode\u003E[a-z]\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Eall lowercase letters within a range\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003E\u003Ccode\u003E[0-9]\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Eall digits\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003E\u003Ccode\u003E.\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Eany character\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003E\u003Ccode\u003E*\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Ezero or more\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003E\u003Ccode\u003E+\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Eone or more\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003E\u003Ccode\u003E( )\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Eif contents within parentheses match, define a group for future reference\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003E\u003Ccode\u003E$1\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Erefer to a matched group (this is the notation in LibreOffice; other notations such as \\\\1 are sometimes used elsewhere)\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003E\u003Ccode\u003E\\\\t\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Etab\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003E\u003Ccode\u003E^\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Ebeginning of line\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003Ctr\u003E\\n\u003Ctd align=\\\"left\\\"\u003E\u003Ccode\u003E$\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\\n\u003Ctd align=\\\"left\\\"\u003Eend of line\u003C\u002Ftd\u003E\\n\u003C\u002Ftr\u003E\\n\u003C\u002Ftbody\u003E\u003C\u002Ftable\u003E\\n\u003Cp\u003EFor a more complete list of regular expressions in LibreOffice, see\\ntheir \u003Ca href=\\\"https:\u002F\u002Fhelp.libreoffice.org\u002FCommon\u002FList_of_Regular_Expressions\\\"\u003EList of Regular Expressions\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"applying-regular-expressions\\\"\u003EApplying regular expressions\u003C\u002Fh2\u003E\\n\u003Cp\u003ELet&#39;s start to use some of these to remove the page headings with date\\nand page number. Switch back to your LibreOffice Writer window.\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace:\u003C\u002Fem\u003E \u003Ccode\u003E^.*February 21.*1908.*$\u003C\u002Fcode\u003E \u003Cem\u003Ewith nothing\u003C\u002Fem\u003E (4 matches).\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E^.*Received out of regular order.*$\u003C\u002Fcode\u003E \u003Cem\u003Ewith nothing\u003C\u002Fem\u003E (2\\nmatches).\u003C\u002Fp\u003E\\n\u003Cp\u003EHere \u003Ccode\u003E^\u003C\u002Fcode\u003E (caret) matches the beginning of the line, \u003Ccode\u003E.\u003C\u002Fcode\u003E (period) matches\\nany character, \u003Ccode\u003E.*\u003C\u002Fcode\u003E (period-asterisk) matches any sequence of zero or\\nmore characters, and \u003Ccode\u003E$\u003C\u002Fcode\u003E (dollar-sign) matches the end of the line. By\\nspelling out the date, we will match only the lines where that sequence\\nappears, letter by letter, and by using \u003Ccode\u003E.*\u003C\u002Fcode\u003E at both ends we match all\\nlines with that sequence regardless of what else is before or after it\\non the line. After making this replacement, we will be left with some\\nblank lines.\u003C\u002Fp\u003E\\n\u003Cp\u003ETo remove the blank lines in LibreOffice,\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E^$\u003C\u002Fcode\u003E \u003Cem\u003Ewith nothing\u003C\u002Fem\u003E (5 matches).\u003C\u002Fp\u003E\\n\u003Cp\u003E(In other regular expression environments, other techniques for working\\nwith line endings will be necessary; some may be more convenient than\\nwhat LibreOffice offers, but this will work now for our purposes.)\u003C\u002Fp\u003E\\n\u003Cp\u003ESome records list a state, some a city with the state implicit, some a\\nstate and city together. The text does not have enough structure to give\\nus a reliable way of distinguishing the California and Oakland records\\nso that we will be able automatically to put California in a state\\ncolumn and Oakland in a city column. We will eventually need to do some\\nediting by hand, drawing on our own knowledge. But there is a lot of\\nconsistency in the references to spans of time. We can use those\\nreferences to develop structures that will help keep similar segments\\naligned across rows.\u003C\u002Fp\u003E\\n\u003Cp\u003EFor convenience, let&#39;s put some markers in the text that won&#39;t be\\nconfused with anything already present. We can easily distinguish these\\nmarkers from existing text, and easily remove them later when we don&#39;t\\nneed them. Let&#39;s match time span references and put &quot;&lt;t&gt;&quot; at the\\nbeginning of them and &quot;&lt;\u002Ft&gt;&quot; at the end, with the mnemonic &quot;t&quot; for\\ntime. We could put a more verbose marker in, like &quot;&lt;time&gt;&quot; or a more\\nmeaningless and untidy-looking one, like &quot;asdfJKL;&quot; as long as that\\nsequence wasn&#39;t for some reason already in our text. But in this\\nexercise we will use markers like &quot;&lt;t&gt;&quot; If you have seen HTML or XML,\\nthese look a lot like the tags that mark elements. We are not creating\\nacceptable HTML or well-formed XML by doing this, and we will remove\\nthese markers quickly, but there is a resemblance.\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cstrong\u003EObligatory warning:\u003C\u002Fstrong\u003E Regular expressions are powerful, but they do\\nhave their limits and (when used to modify material that someone cares\\nabout) they can be dangerous, in that a mistake can inadvertently remove\\nor scramble a lot of information quickly. Also, as XML aficionados may\\npassionately tell you, regular expressions are not up to the job of\\ngeneral-purpose parsing of XML. After one sees how useful regular\\nexpressions are at dealing with certain kinds of patterns, there is a\\ntemptation to think, whenever we see a pattern that a computer ought to\\nbe able to help with, that regular expressions are all we need. In many\\ncases that will turn out not to be true. Regular expressions are not\\nadequate to deal with hierarchically nested patterns that XML is good at\\ndescribing.\u003C\u002Fp\u003E\\n\u003Cp\u003EBut that&#39;s OK. In the context of this tutorial, we don&#39;t claim to know\\nanything in particular about XML, or to care about formal language\\ngrammars. We just want to put some convenient markers into a text in\\norder to get some leverage in making a relatively simple implicit\\nstructure a bit more explicit, and we will take those markers out before\\nwe are done. There is a reason why such markers are useful. If you find\\nyourself intrigued by what can be done with patterns in this exercise,\\nyou may want to learn more about HTML and XML, and learn what can be\\ndone with appropriate methods that their more explicit structure makes\\npossible.\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"defining-segments\\\"\u003EDefining segments\u003C\u002Fh2\u003E\\n\u003Cp\u003EThe next few patterns will rapidly get more complicated. If you slow\\ndown to consult the reference to how the symbols define patterns,\\nhowever, the patterns should start to make sense.\u003C\u002Fp\u003E\\n\u003Cp\u003EGeographic references in our text are followed by emdashes (dashes that\\nare roughly the width of the letter &#39;m&#39;; wider than endashes.) We can\\nreplace these with tab characters, which will effectively help us put\\nstates and cities in separate columns of the spreadsheet.\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E[ ]?—[ ]?\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E\\\\t\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003EYou should have 42 matches. (One easy way to get the emdash into your\\npattern is to copy and paste from an existing emdash in the text itself.\\nThe square brackets aren&#39;t entirely necessary here, but help make\\nvisible the fact that we are matching a blank space — optionally\\nmatching it, thanks to the question mark. That means our pattern will\\naccept an emdash with or without a space on either or both sides of it.)\u003C\u002Fp\u003E\\n\u003Cp\u003ENow we will look for explicit references to time and wrap them in\\n&quot;&lt;t&gt;&quot; and &quot;&lt;\u002Ft&gt;&quot; markers before and after. Once we have those\\nmarkers they will provide some scaffolding on which we can build further\\npatterns. Note that in the next pattern we want to be sure to apply the\\nreplacement just once, otherwise some time references may be repeatedly\\nwrapped. It will be most efficient to use \u003Ccode\u003EReplace All\u003C\u002Fcode\u003E just once for\\neach wrapping pattern.\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E(Month of [A-Z][a-z, 0-9]+ 19[0-9][0-9].)\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E&lt;t&gt;$1&lt;\u002Ft&gt;\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;regex_06_timemarkup.png&quot; caption=&quot;Figure 7: Finding time using Regular Expressions&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003EHere we are using parentheses to define everything that we match in the\\nsearch pattern as a single group, and in the replacement pattern we use\\n$1 to simply repeat that match, with a few additional characters before\\nand after it.\u003C\u002Fp\u003E\\n\u003Cp\u003EIn addition to months, we need to match quarterly reports with a similar\\napproach:\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E([-A-Za-z ]+ ended [A-Z][a-z, 0-9]+ 19[0-9][0-9].)\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E&lt;t&gt;$1&lt;\u002Ft&gt;\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003EYou should have 7 more matches. It looks like we have references to time\\naccounted for. Extending this strategy to other kinds of information\\nhere, let&#39;s use &quot;&lt;p&gt;&quot; for population estimates, &quot;&lt;N&gt;&quot; for total\\nnumber of deaths, and &quot;&lt;c&gt;&quot; for the word &quot;Cases,&quot; which separates\\nmortality from morbidity. (If you are familiar with HTML or XML, you may\\nrecognize &quot;&lt;p&gt;&quot; as a paragraph marker. We&#39;re not using it in the same\\nway here.)\u003C\u002Fp\u003E\\n\u003Cp\u003EHere are some patterns to wrap each of those kinds of information, all\\nusing the same strategy we just used:\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E(Estimated population, [0-9,]+.)\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E&lt;p&gt;$1&lt;\u002Fp&gt;\u003C\u002Fcode\u003E (34 matches).\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E(Total number of deaths[A-Za-z ,]* [0-9,]+)\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E&lt;N&gt;$1&lt;\u002FN&gt;\u003C\u002Fcode\u003E (48 matches).\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E(Cases ?:)\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E&lt;c&gt;$1&lt;\u002Fc&gt;\u003C\u002Fcode\u003E (49 matches).\u003C\u002Fp\u003E\\n\u003Cp\u003EThis next part is a little trickier. It would be great if we could get\\nhold of the disease (let&#39;s use &quot;&lt;d&gt;&quot;) and count (&quot;&lt;n&gt;&quot;) segments.\\nBecause the prose in this document is so formulaic, especially following\\nthe indication of total number of deaths, in this case we will be able\\nto get pretty far without having to match each disease name explicitly,\\none by one. First match the disease-count pair after the word\\n&quot;including&quot;:\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E&lt;\u002FN&gt; including ([A-Za-z ]+) ([0-9]+),\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E&lt;\u002FN&gt; including &lt;d&gt;$1&lt;\u002Fd&gt; &lt;n&gt;$2&lt;\u002Fn&gt;\u003C\u002Fcode\u003E (29 matches).\u003C\u002Fp\u003E\\n\u003Cp\u003EAnd then iteratively match disease-count pairs that appear after\\nexisting markers:\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E&gt; ([A-Za-z ]+) ([0-9]+)([.,])\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E&gt; &lt;d&gt;$1&lt;\u002Fd&gt; &lt;n&gt;$2&lt;\u002Fn&gt;\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003ENote that we are getting rid of commas after the disease counts by\\nignoring the third match in our replacement.\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cstrong\u003ERepeat\u003C\u002Fstrong\u003E this replacement as many times as necessary until there are\\nno further matches. It should take you seven iterations.\u003C\u002Fp\u003E\\n\u003Cp\u003EOur patterns have not done anything with phrases like &#39;and 3 from\\ntuberculosis.&#39; We can match those phrases and reverse the order so that\\nthe disease name appears before the count:\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003Eand ([0-9])+ from ([a-z ]+)\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E&lt;d&gt;$2&lt;\u002Fd&gt; &lt;n&gt;$1&lt;\u002Fn&gt;\u003C\u002Fcode\u003E (32 matches).\u003C\u002Fp\u003E\\n\u003Cp\u003EIt looks like our markers are now capturing a lot of the semantic\\nstructure that we are interested in. Now let&#39;s copy and paste (&quot;paste\\nspecial … unformatted&quot;) into LibreOffice Calc to see how close we are to\\ngetting a table. We are successfully separating location data into\\ncells, but the cells are not aligned vertically yet. We want to get all\\nof the time references into the third column.\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;regex_09_calc_3col.png&quot; caption=&quot;Figure 8: Measuring progress using LibreOffice Calc&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003EThe instances with two columns of location information should already be\\nOK. The rows with one location need an extra column. Most are cities, so\\nwe will put the locations into the second column, and in a few instances\\nwe will need to move state names back to the first column by hand. Go\\nback to your LibreOffice Writer window and:\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E^([A-Za-z .]+\\\\t&lt;t&gt;)\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E\\\\t$1\u003C\u002Fcode\u003E (30 matches).\u003C\u002Fp\u003E\\n\u003Cp\u003ENow fix the cases with no location information, where the location is\\nimplicitly the same as the row above, and the time span is different.\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E^&lt;t&gt;\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E\\\\t\\\\t&lt;t&gt;\u003C\u002Fcode\u003E (19 matches)\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;regex_10_loc_columns.png&quot; caption=&quot;Figure 9: Further refining the results&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003EThe first few columns should look better after pasting this again into\\nCalc. The Writer text is still our working copy, so if you want to fix\\nup the state names, you could do so now in Writer by deleting the tab\\ncharacter before a state name and introducing a new tab character after\\nit. Or you could wait until we are done with our work in Writer, and fix\\nthem in Calc after we are ready for that to be our live working copy.\\nBut we are not there yet.\u003C\u002Fp\u003E\\n\u003Cp\u003EWe need to decide how to handle the lists of diseases. The rows have\\ndifferent lists of varying lengths. While it would be easy enough now to\\ninsert tab characters to put each disease and mortality or morbidity\\ncount into a separate column, the columns would not be that helpful.\\nDiseases and tallies would not be vertically aligned. What we can do\\ninstead is make a new row for each disease. The reports distinguish\\nbetween mortality counts and morbidity counts, which are already\\nconveniently separated by &quot;Cases:&quot;. (There is one case, Indiana, where\\nthe text marks this section with the word &quot;Morbidity&quot;. Our searching\\npatterns missed this. You can fix the markup there by hand now, if you\\nlike, or ignore it since this is an exercise. It&#39;s a good example of how\\nautomated tools aren&#39;t a full substitute for editing or looking at your\\nsources, and it won&#39;t be the last such example.)\u003C\u002Fp\u003E\\n\u003Cp\u003EWe can start by making a new row for &quot;cases&quot; lists, so that we can\\nhandle them separately. Head back to LibreOffice Writer.\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;regex_11_writer_cases_together_hi.png&quot; caption=&quot;Figure 10: Making a new row for &#39;cases&#39;&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E^(.*\\\\t)(.*\\\\t)(&lt;t&gt;.*&lt;\u002Ft&gt;)(.*)(&lt;c&gt;.*)\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E$1$2$3$4\\\\n$1$2$3\\\\t$5\u003C\u002Fcode\u003E (47 matches).\u003C\u002Fp\u003E\\n\u003Cp\u003EOne thing to notice here is that we are using some of the replacement\\npatterns twice. We are matching the three fields up to the time\\nreference, then matching everything before &quot;&lt;c&gt;&quot; in a fourth group,\\nand everything from &quot;&lt;c&gt;&quot; on in a fifth. In the replacement pattern,\\nwe put groups 1-4 back in order, then introduce a newline and print\\ngroups 1-3 again, followed by a tab and group 5. We&#39;ve effectively moved\\nthe case listings to their own lines, and copied the place and time\\nfields verbatim.\u003C\u002Fp\u003E\\n\u003Cp\u003ELet&#39;s go further, and split all the case lists into separate rows:\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E^(.*\\\\t)(.*\\\\t)(&lt;t&gt;.*&lt;\u002Ft&gt;)(.*&lt;c&gt;.*)(&lt;d&gt;.*&lt;\u002Fd&gt;) (&lt;n&gt;.*&lt;\u002Fn&gt;)\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E$1$2$3$4\\\\n$1$2$3\\\\tCases\\\\t$5$6\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003Eand \u003Cstrong\u003Erepeat\u003C\u002Fstrong\u003E as many times as necessary until there are no more\\nreplacements (seven iterations).\u003C\u002Fp\u003E\\n\u003Cp\u003ENow similarly split all the mortality lists into separate rows:\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E^(.*\\\\t)(.*\\\\t)(&lt;t&gt;.*&lt;\u002Ft&gt;)(.*&lt;N&gt;.*)(&lt;d&gt;.*&lt;\u002Fd&gt;) (&lt;n&gt;.*&lt;\u002Fn&gt;)\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E$1$2$3$4\\\\n$1$2$3\\\\tDeaths\\\\t$5$6\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003Eand \u003Cstrong\u003Erepeat\u003C\u002Fstrong\u003E as many times as necessary until there are no more\\nreplacements (eight iterations).\u003C\u002Fp\u003E\\n\u003Cp\u003EThis is getting very close now to a tabular structure, as you can see if\\nyou paste again into Calc, though if you want to wait just a bit, some\\ncleanup work with short and simple patterns will get us most of the rest\\nof the way:\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E.*&lt;\u002Fc&gt; $\u003C\u002Fcode\u003E \u003Cem\u003Ewith nothing\u003C\u002Fem\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E^$\u003C\u002Fcode\u003E \u003Cem\u003Ewith nothing\u003C\u002Fem\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E&lt;n&gt;\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E\\\\t\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E&lt;\u002Fn&gt;\u003C\u002Fcode\u003E \u003Cem\u003Ewith nothing\u003C\u002Fem\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E&lt;d&gt;and\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003Ewith\u003C\u002Fem\u003E \u003Ccode\u003E&lt;d&gt;\u003C\u002Fcode\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EReplace\u003C\u002Fem\u003E \u003Ccode\u003E&lt;\u002F?[tdp]&gt;\u003C\u002Fcode\u003E \u003Cem\u003Ewith nothing\u003C\u002Fem\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;regex_17_writer_done.png&quot; caption=&quot;Figure 11: The final view in LibreOffice Writer&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003ENow copy and paste this into Calc, and you should see a (mostly)\\nwell-structured table.\u003C\u002Fp\u003E\\n\u003Cp\u003E{% include figure.html filename=&quot;regex_18_calc_done.png&quot; caption=&quot;Figure 12: The final view in LibreOffice Calc&quot; %}\u003C\u002Fp\u003E\\n\u003Cp\u003EIf this were not an exercise but a source we were editing for research\\nor publication, there are still things that we would need to fix. We\\ndidn&#39;t do anything with estimated population figures. Our\\npattern-matching wasn&#39;t sophisticated enough to manage everything. In\\nlines that didn&#39;t have patterns like &quot;Total number of deaths 292,\\nincluding,&quot; we missed all subsequent patterns that assumed we had\\nalready put in an &quot;&lt;\u002FN&gt;&quot; marker.\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"next-possibilities\\\"\u003ENext possibilities\u003C\u002Fh2\u003E\\n\u003Cp\u003ESome of these problems could be fixed by additional pattern-matching\\nsteps, some by hand-editing of the source document at particular points\\nalong the way, and some by later editing of the data in spreadsheet or\\nsimilar tabular form.\u003C\u002Fp\u003E\\n\u003Cp\u003EWe might want to consider other structures for the table, too — perhaps\\nmortality and morbidity would be more convenient to tally if they were\\nin different columns. Word processors are not the best tools for making\\nuse of these kinds of structures. Spreadsheets, XML, and programmatic\\ntools for working with data are much more likely to be helpful. But word\\nprocessors do have advanced find-and-replace functions that are good to\\nget to know. Regular expressions and advanced pattern matching can be\\nhelpful in editing, and can provide a bridge between sequences with\\nimplicit structure and more explicit structures that we may want to\\nmatch or create.\u003C\u002Fp\u003E\\n\u003Cp\u003EThere are more than 400 public health reports like this one available\\nfrom the Internet Archive. If we wanted to tabulate all of them,\\nLibreOffice would not be the best primary tool. It would be better to\\nlearn a little Python, Ruby, or shell scripting. Programmer-oriented\\nplain text editors, including classic ones such as Emacs and Vi or Vim,\\nhave great regular expression support as well as other features useful\\nfor dealing with plain text in a programmatic way. If you are\\ncomfortable opening up a Unix-like shell command line (in Mac or Linux,\\nor on Windows through a virtual machine or the Cygwin environment), you\\ncan learn and use regular expressions very well with tools like &quot;grep&quot;\\nfor searching and &quot;sed&quot; for line-oriented replacing.\u003C\u002Fp\u003E\\n\u003Cp\u003ERegular expressions can be immensely useful in dealing with patterns\\nacross hundreds of files at once. The patterns we have used in this\\nexample would need to be refined and extended to deal with assumptions\\nthat are certain to be mistaken when applied to longer texts or larger\\nsets of texts, but with a programming language we could record what we\\nare doing in a short script, and refine and rerun it repeatedly to get\\ncloser to what we want.\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"to-learn-more\\\"\u003ETo learn more\u003C\u002Fh2\u003E\\n\u003Cp\u003EThe Wikipedia page on \u003Ca href=\\\"http:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FRegular_expressions\\\"\u003Eregular expressions\u003C\u002Fa\u003E is a useful place to find\\na brief history of regular expressions and their relation to formal\\nlanguage theory, as well as an overview of syntactic variants and formal\\nstandardization efforts.\u003C\u002Fp\u003E\\n\u003Cp\u003EThe documentation for whatever tools you use will be invaluable for\\npractical use, especially for work in word processing environments where\\nregular expression implementations may be especially idiosyncratic.\\nThere are many resources available to learn how to use regular\\nexpressions in programming contexts; which is best for you may depend on\\nwhat programming language is most familiar or convenient to start with.\u003C\u002Fp\u003E\\n\u003Cp\u003EThere are a number of freely available web-based regular expression\\neditors. \u003Ca href=\\\"http:\u002F\u002Frubular.com\u002F\\\"\u003ERubular\u003C\u002Fa\u003E, built on the Ruby programming language, has a\\nhelpful interface that lets you test regular expressions against a\\nsample text and dynamically shows matches and matched groups. David\\nBirnbaum, Chair of the Department of Slavic Languages and Literatures at\\nthe University of Pittsburg, has some good materials on how to work with\\n\u003Ca href=\\\"http:\u002F\u002Fdh.obdurodon.org\u002Fregex.html\\\"\u003Eregular expressions and XML tools\u003C\u002Fa\u003E to help mark up plain-text files\\nin TEI XML.\u003C\u002Fp\u003E\\n\"}"}</script></div>
	</body>
</html>
